<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />
    <link rel="apple-touch-icon" sizes="180x180" href="_static/apple-touch-icon.png" type="image/png">
    <link rel="icon" type="image/png" sizes="32x32" href="_static/favicon-32x32.png">
    <link rel="icon" type="image/png" sizes="16x16" href="_static/favicon-16x16.png">
    <link rel="manifest" href="_static/site.webmanifest">
    <link rel="mask-icon" href="_static/safari-pinned-tab.svg" color="#5bbad5" type="image/svg+xml">
    <meta name="msapplication-TileColor" content="#ed1c24">
    <meta name="theme-color" content="#ed1c24">
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  
<!-- OneTrust Cookies Consent Notice start for xilinx.github.io -->

<script src="https://cdn.cookielaw.org/scripttemplates/otSDKStub.js" data-document-language="true" type="text/javascript" charset="UTF-8" data-domain-script="03af8d57-0a04-47a6-8f10-322fa00d8fc7" ></script>
<script type="text/javascript">
function OptanonWrapper() { }
</script>
<!-- OneTrust Cookies Consent Notice end for xilinx.github.io -->
<!-- Google Tag Manager -->
<script type="text/plain" class="optanon-category-C0002">(function(w,d,s,l,i){w[l]=w[l]||[];w[l].push({'gtm.start':
new Date().getTime(),event:'gtm.js'});var f=d.getElementsByTagName(s)[0],
j=d.createElement(s),dl=l!='dataLayer'?'&l='+l:'';j.async=true;j.src=
'//www.googletagmanager.com/gtm.js?id='+i+dl;f.parentNode.insertBefore(j,f);
})(window,document,'script','dataLayer','GTM-5RHQV7');</script>
<!-- End Google Tag Manager -->
  <title>Client API &mdash; AMD Inference Server</title>
      <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
      <link rel="stylesheet" href="_static/css/theme.css" type="text/css" />
      <link rel="stylesheet" href="_static/copybutton.css" type="text/css" />
      <link rel="stylesheet" href="_static/twemoji.css" type="text/css" />
      <link rel="stylesheet" href="_static/tabs.css" type="text/css" />
      <link rel="stylesheet" href="_static/custom.css" type="text/css" />
      <link rel="stylesheet" href="https://cdn.datatables.net/1.13.4/css/jquery.dataTables.min.css" type="text/css" />
  <!--[if lt IE 9]>
    <script src="_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script data-url_root="./" id="documentation_options" src="_static/documentation_options.js"></script>
        <script src="_static/jquery.js"></script>
        <script src="_static/underscore.js"></script>
        <script src="_static/doctools.js"></script>
        <script src="_static/clipboard.min.js"></script>
        <script src="_static/copybutton.js"></script>
        <script src="https://twemoji.maxcdn.com/v/latest/twemoji.min.js"></script>
        <script src="_static/twemoji.js"></script>
        <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-svg.js"></script>
        <script src="_static/tabs.js"></script>
        <script defer="defer" src="https://unpkg.com/@popperjs/core@2"></script>
        <script defer="defer" src="https://unpkg.com/tippy.js@6"></script>
        <script defer="defer" src="_static/tippy/client_api.c59b05ba-bb5b-43cf-ac7c-ee646858b1e4.js"></script>
        <script src="https://cdn.datatables.net/1.13.4/js/jquery.dataTables.min.js"></script>
        <script src="_static/dataTables.js"></script>
    <script src="_static/js/theme.js"></script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="KServe" href="kserve.html" />
    <link rel="prev" title="Deployment" href="deployment.html" /> 
</head>

<body class="wy-body-for-nav">

<!-- Google Tag Manager -->
<noscript><iframe src="//www.googletagmanager.com/ns.html?id=GTM-5RHQV7" height="0" width="0" style="display:none;visibility:hidden" class="optanon-category-C0002"></iframe></noscript>
<!-- End Google Tag Manager --> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search">
            <a href="index.html" class="icon icon-home"> AMD Inference Server
            <img src="_static/xilinx-header-logo.svg" class="logo" alt="Logo"/>
          </a>
              <div class="version">
                0.4.0
              </div>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">Getting started</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="introduction.html">Introduction</a><ul>
<li class="toctree-l2"><a class="reference internal" href="introduction.html#features">Features</a></li>
<li class="toctree-l2"><a class="reference internal" href="introduction.html#documentation-overview">Documentation overview</a></li>
<li class="toctree-l2"><a class="reference internal" href="introduction.html#support">Support</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="terminology.html">Terminology</a><ul>
<li class="toctree-l2"><a class="reference internal" href="terminology.html#amdinfer">amdinfer</a></li>
<li class="toctree-l2"><a class="reference internal" href="terminology.html#types-of-docker-images">Types of Docker images</a><ul>
<li class="toctree-l3"><a class="reference internal" href="terminology.html#development">Development</a></li>
<li class="toctree-l3"><a class="reference internal" href="terminology.html#deployment">Deployment</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="terminology.html#types-of-users">Types of users</a><ul>
<li class="toctree-l3"><a class="reference internal" href="terminology.html#clients">Clients</a></li>
<li class="toctree-l3"><a class="reference internal" href="terminology.html#administrators">Administrators</a></li>
<li class="toctree-l3"><a class="reference internal" href="terminology.html#developers">Developers</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="quickstart.html">Quickstart</a><ul>
<li class="toctree-l2"><a class="reference internal" href="quickstart.html#prerequisites">Prerequisites</a></li>
<li class="toctree-l2"><a class="reference internal" href="quickstart.html#prepare-the-model-repository">Prepare the model repository</a></li>
<li class="toctree-l2"><a class="reference internal" href="quickstart.html#get-the-deployment-image">Get the deployment image</a></li>
<li class="toctree-l2"><a class="reference internal" href="quickstart.html#start-the-image">Start the image</a></li>
<li class="toctree-l2"><a class="reference internal" href="quickstart.html#server-deployment-summary">Server deployment summary</a></li>
<li class="toctree-l2"><a class="reference internal" href="quickstart.html#get-the-python-library">Get the Python library</a></li>
<li class="toctree-l2"><a class="reference internal" href="quickstart.html#running-an-example">Running an example</a></li>
<li class="toctree-l2"><a class="reference internal" href="quickstart.html#inference-summary">Inference summary</a></li>
<li class="toctree-l2"><a class="reference internal" href="quickstart.html#next-steps">Next steps</a></li>
</ul>
</li>
</ul>
<p class="caption" role="heading"><span class="caption-text">User guide</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="backends.html">Backends</a><ul>
<li class="toctree-l2"><a class="reference internal" href="backends/cplusplus.html">CPlusPlus</a><ul>
<li class="toctree-l3"><a class="reference internal" href="backends/cplusplus.html#model-support">Model support</a></li>
<li class="toctree-l3"><a class="reference internal" href="backends/cplusplus.html#hardware-support">Hardware support</a></li>
<li class="toctree-l3"><a class="reference internal" href="backends/cplusplus.html#host-setup">Host setup</a></li>
<li class="toctree-l3"><a class="reference internal" href="backends/cplusplus.html#build-an-image">Build an image</a></li>
<li class="toctree-l3"><a class="reference internal" href="backends/cplusplus.html#start-a-container">Start a container</a></li>
<li class="toctree-l3"><a class="reference internal" href="backends/cplusplus.html#get-test-assets">Get test assets</a></li>
<li class="toctree-l3"><a class="reference internal" href="backends/cplusplus.html#loading-the-backend">Loading the backend</a></li>
<li class="toctree-l3"><a class="reference internal" href="backends/cplusplus.html#troubleshooting">Troubleshooting</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="backends/migraphx.html">MIGraphX</a><ul>
<li class="toctree-l3"><a class="reference internal" href="backends/migraphx.html#model-support">Model support</a></li>
<li class="toctree-l3"><a class="reference internal" href="backends/migraphx.html#hardware-support">Hardware support</a></li>
<li class="toctree-l3"><a class="reference internal" href="backends/migraphx.html#host-setup">Host setup</a></li>
<li class="toctree-l3"><a class="reference internal" href="backends/migraphx.html#build-an-image">Build an image</a></li>
<li class="toctree-l3"><a class="reference internal" href="backends/migraphx.html#start-a-container">Start a container</a></li>
<li class="toctree-l3"><a class="reference internal" href="backends/migraphx.html#get-test-assets">Get test assets</a></li>
<li class="toctree-l3"><a class="reference internal" href="backends/migraphx.html#loading-the-backend">Loading the backend</a></li>
<li class="toctree-l3"><a class="reference internal" href="backends/migraphx.html#troubleshooting">Troubleshooting</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="backends/ptzendnn.html">PtZenDNN</a><ul>
<li class="toctree-l3"><a class="reference internal" href="backends/ptzendnn.html#model-support">Model support</a></li>
<li class="toctree-l3"><a class="reference internal" href="backends/ptzendnn.html#hardware-support">Hardware support</a></li>
<li class="toctree-l3"><a class="reference internal" href="backends/ptzendnn.html#host-setup">Host setup</a></li>
<li class="toctree-l3"><a class="reference internal" href="backends/ptzendnn.html#build-an-image">Build an image</a></li>
<li class="toctree-l3"><a class="reference internal" href="backends/ptzendnn.html#start-a-container">Start a container</a></li>
<li class="toctree-l3"><a class="reference internal" href="backends/ptzendnn.html#get-test-assets">Get test assets</a></li>
<li class="toctree-l3"><a class="reference internal" href="backends/ptzendnn.html#loading-the-backend">Loading the backend</a></li>
<li class="toctree-l3"><a class="reference internal" href="backends/ptzendnn.html#troubleshooting">Troubleshooting</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="backends/tfzendnn.html">TfZenDNN</a><ul>
<li class="toctree-l3"><a class="reference internal" href="backends/tfzendnn.html#model-support">Model support</a></li>
<li class="toctree-l3"><a class="reference internal" href="backends/tfzendnn.html#hardware-support">Hardware support</a></li>
<li class="toctree-l3"><a class="reference internal" href="backends/tfzendnn.html#host-setup">Host setup</a></li>
<li class="toctree-l3"><a class="reference internal" href="backends/tfzendnn.html#build-an-image">Build an image</a></li>
<li class="toctree-l3"><a class="reference internal" href="backends/tfzendnn.html#start-a-container">Start a container</a></li>
<li class="toctree-l3"><a class="reference internal" href="backends/tfzendnn.html#get-test-assets">Get test assets</a></li>
<li class="toctree-l3"><a class="reference internal" href="backends/tfzendnn.html#loading-the-backend">Loading the backend</a></li>
<li class="toctree-l3"><a class="reference internal" href="backends/tfzendnn.html#troubleshooting">Troubleshooting</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="backends/vitis_ai.html">Vitis AI</a><ul>
<li class="toctree-l3"><a class="reference internal" href="backends/vitis_ai.html#model-support">Model support</a></li>
<li class="toctree-l3"><a class="reference internal" href="backends/vitis_ai.html#hardware-support">Hardware support</a></li>
<li class="toctree-l3"><a class="reference internal" href="backends/vitis_ai.html#host-setup">Host setup</a></li>
<li class="toctree-l3"><a class="reference internal" href="backends/vitis_ai.html#build-an-image">Build an image</a></li>
<li class="toctree-l3"><a class="reference internal" href="backends/vitis_ai.html#start-a-container">Start a container</a></li>
<li class="toctree-l3"><a class="reference internal" href="backends/vitis_ai.html#get-test-assets">Get test assets</a></li>
<li class="toctree-l3"><a class="reference internal" href="backends/vitis_ai.html#loading-the-backend">Loading the backend</a></li>
<li class="toctree-l3"><a class="reference internal" href="backends/vitis_ai.html#troubleshooting">Troubleshooting</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="model_repository.html">Model Repository</a><ul>
<li class="toctree-l2"><a class="reference internal" href="model_repository.html#single-models">Single models</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_repository.html#ensembles">Ensembles</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="ensembles.html">Ensembles</a><ul>
<li class="toctree-l2"><a class="reference internal" href="ensembles.html#defining-ensembles">Defining ensembles</a><ul>
<li class="toctree-l3"><a class="reference internal" href="ensembles.html#model-repository">Model repository</a></li>
<li class="toctree-l3"><a class="reference internal" href="ensembles.html#api">API</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="deployment.html">Deployment</a><ul>
<li class="toctree-l2"><a class="reference internal" href="deployment.html#deployment-image">Deployment image</a><ul>
<li class="toctree-l3"><a class="reference internal" href="deployment.html#get-the-image">Get the image</a></li>
<li class="toctree-l3"><a class="reference internal" href="deployment.html#build-the-image">Build the image</a></li>
<li class="toctree-l3"><a class="reference internal" href="deployment.html#push-to-a-registry">Push to a registry</a></li>
<li class="toctree-l3"><a class="reference internal" href="deployment.html#prepare-the-image">Prepare the image</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="deployment.html#start-a-container">Start a container</a></li>
<li class="toctree-l2"><a class="reference internal" href="deployment.html#kserve">KServe</a></li>
<li class="toctree-l2"><a class="reference internal" href="deployment.html#development-image">Development image</a></li>
</ul>
</li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">Client API</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#include-the-api">Include the API</a></li>
<li class="toctree-l2"><a class="reference internal" href="#create-a-client-object">Create a client object</a></li>
<li class="toctree-l2"><a class="reference internal" href="#server-status">Server status</a></li>
<li class="toctree-l2"><a class="reference internal" href="#loading-a-backend">Loading a backend</a></li>
<li class="toctree-l2"><a class="reference internal" href="#making-an-inference-request">Making an inference request</a></li>
<li class="toctree-l2"><a class="reference internal" href="#parsing-the-response">Parsing the response</a></li>
<li class="toctree-l2"><a class="reference internal" href="#next-steps">Next steps</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="kserve.html">KServe</a><ul>
<li class="toctree-l2"><a class="reference internal" href="kserve.html#set-up-kubernetes-and-kserve">Set up Kubernetes and KServe</a></li>
<li class="toctree-l2"><a class="reference internal" href="kserve.html#get-or-build-the-amd-inference-server-image">Get or build the AMD Inference Server Image</a></li>
<li class="toctree-l2"><a class="reference internal" href="kserve.html#start-an-inference-service">Start an inference service</a><ul>
<li class="toctree-l3"><a class="reference internal" href="kserve.html#serving-runtime">Serving Runtime</a></li>
<li class="toctree-l3"><a class="reference internal" href="kserve.html#custom-container">Custom container</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="kserve.html#making-requests">Making Requests</a></li>
<li class="toctree-l2"><a class="reference internal" href="kserve.html#debugging">Debugging</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="performance.html">Performance</a><ul>
<li class="toctree-l2"><a class="reference internal" href="performance.html#mlcommons">MLCommons</a><ul>
<li class="toctree-l3"><a class="reference internal" href="performance.html#singlestream">SingleStream</a></li>
<li class="toctree-l3"><a class="reference internal" href="performance.html#server">Server</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="performance_factors.html">Performance Factors</a><ul>
<li class="toctree-l2"><a class="reference internal" href="performance_factors.html#hardware">Hardware</a></li>
<li class="toctree-l2"><a class="reference internal" href="performance_factors.html#compile-the-right-version">Compile the right version</a></li>
<li class="toctree-l2"><a class="reference internal" href="performance_factors.html#parallelism">Parallelism</a><ul>
<li class="toctree-l3"><a class="reference internal" href="performance_factors.html#rest-threads">REST threads</a></li>
<li class="toctree-l3"><a class="reference internal" href="performance_factors.html#sending-requests">Sending requests</a></li>
<li class="toctree-l3"><a class="reference internal" href="performance_factors.html#duplicating-workers">Duplicating workers</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="troubleshooting.html">Troubleshooting</a><ul>
<li class="toctree-l2"><a class="reference internal" href="troubleshooting.html#use-the-latest-version">Use the latest version</a></li>
<li class="toctree-l2"><a class="reference internal" href="troubleshooting.html#use-server-logs">Use server logs</a></li>
<li class="toctree-l2"><a class="reference internal" href="troubleshooting.html#build-errors">Build errors</a></li>
</ul>
</li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Examples</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="hello_world_echo.html">Hello World - Python</a><ul>
<li class="toctree-l2"><a class="reference internal" href="hello_world_echo.html#import-the-library">Import the library</a></li>
<li class="toctree-l2"><a class="reference internal" href="hello_world_echo.html#create-our-client-and-server-objects">Create our client and server objects</a></li>
<li class="toctree-l2"><a class="reference internal" href="hello_world_echo.html#is-amd-inference-server-already-running">Is AMD Inference Server already running?</a></li>
<li class="toctree-l2"><a class="reference internal" href="hello_world_echo.html#load-a-worker">Load a worker</a></li>
<li class="toctree-l2"><a class="reference internal" href="hello_world_echo.html#inference">Inference</a></li>
<li class="toctree-l2"><a class="reference internal" href="hello_world_echo.html#validate-the-response">Validate the response</a></li>
<li class="toctree-l2"><a class="reference internal" href="hello_world_echo.html#clean-up">Clean up</a></li>
<li class="toctree-l2"><a class="reference internal" href="hello_world_echo.html#next-steps">Next steps</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="example_resnet50_cpp.html">Running ResNet50 - C++</a><ul>
<li class="toctree-l2"><a class="reference internal" href="example_resnet50_cpp.html#include-the-header">Include the header</a></li>
<li class="toctree-l2"><a class="reference internal" href="example_resnet50_cpp.html#start-the-server">Start the server</a></li>
<li class="toctree-l2"><a class="reference internal" href="example_resnet50_cpp.html#create-the-client-object">Create the client object</a></li>
<li class="toctree-l2"><a class="reference internal" href="example_resnet50_cpp.html#load-a-worker">Load a worker</a></li>
<li class="toctree-l2"><a class="reference internal" href="example_resnet50_cpp.html#prepare-images">Prepare images</a></li>
<li class="toctree-l2"><a class="reference internal" href="example_resnet50_cpp.html#construct-requests">Construct requests</a></li>
<li class="toctree-l2"><a class="reference internal" href="example_resnet50_cpp.html#make-an-inference">Make an inference</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="example_resnet50_python.html">Running ResNet50 - Python</a><ul>
<li class="toctree-l2"><a class="reference internal" href="example_resnet50_python.html#include-the-module">Include the module</a></li>
<li class="toctree-l2"><a class="reference internal" href="example_resnet50_python.html#start-the-server">Start the server</a></li>
<li class="toctree-l2"><a class="reference internal" href="example_resnet50_python.html#create-the-client-object">Create the client object</a></li>
<li class="toctree-l2"><a class="reference internal" href="example_resnet50_python.html#load-a-worker">Load a worker</a></li>
<li class="toctree-l2"><a class="reference internal" href="example_resnet50_python.html#prepare-images">Prepare images</a></li>
<li class="toctree-l2"><a class="reference internal" href="example_resnet50_python.html#construct-requests">Construct requests</a></li>
<li class="toctree-l2"><a class="reference internal" href="example_resnet50_python.html#make-an-inference">Make an inference</a></li>
</ul>
</li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Developers</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="quickstart_development.html">Developer Quickstart</a><ul>
<li class="toctree-l2"><a class="reference internal" href="quickstart_development.html#prerequisites">Prerequisites</a></li>
<li class="toctree-l2"><a class="reference internal" href="quickstart_development.html#set-up-the-host">Set up the host</a></li>
<li class="toctree-l2"><a class="reference internal" href="quickstart_development.html#get-the-code">Get the code</a></li>
<li class="toctree-l2"><a class="reference internal" href="quickstart_development.html#amdinfer-script">amdinfer script</a></li>
<li class="toctree-l2"><a class="reference internal" href="quickstart_development.html#build-or-get-the-docker-image">Build or get the Docker image</a></li>
<li class="toctree-l2"><a class="reference internal" href="quickstart_development.html#compiling-the-amd-inference-server">Compiling the AMD Inference Server</a></li>
<li class="toctree-l2"><a class="reference internal" href="quickstart_development.html#get-test-artifacts">Get test artifacts</a></li>
<li class="toctree-l2"><a class="reference internal" href="quickstart_development.html#run-the-amd-inference-server">Run the AMD Inference Server</a></li>
<li class="toctree-l2"><a class="reference internal" href="quickstart_development.html#next-steps">Next steps</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="testing.html">Testing</a><ul>
<li class="toctree-l2"><a class="reference internal" href="testing.html#add-a-new-test">Add a new test</a><ul>
<li class="toctree-l3"><a class="reference internal" href="testing.html#add-assets">Add assets</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="architecture.html">Architecture</a><ul>
<li class="toctree-l2"><a class="reference internal" href="architecture.html#overview">Overview</a></li>
<li class="toctree-l2"><a class="reference internal" href="architecture.html#ingestion">Ingestion</a><ul>
<li class="toctree-l3"><a class="reference internal" href="architecture.html#api">API</a></li>
<li class="toctree-l3"><a class="reference internal" href="architecture.html#http-rest-and-websocket">HTTP/REST and WebSocket</a></li>
<li class="toctree-l3"><a class="reference internal" href="architecture.html#grpc">gRPC</a></li>
<li class="toctree-l3"><a class="reference internal" href="architecture.html#c-api">C++ API</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="architecture.html#batching">Batching</a></li>
<li class="toctree-l2"><a class="reference internal" href="architecture.html#workers">Workers</a><ul>
<li class="toctree-l3"><a class="reference internal" href="architecture.html#organization-and-lifecycle">Organization and Lifecycle</a></li>
<li class="toctree-l3"><a class="reference internal" href="architecture.html#improving-performance">Improving Performance</a></li>
<li class="toctree-l3"><a class="reference internal" href="architecture.html#external-processing">External Processing</a></li>
<li class="toctree-l3"><a class="reference internal" href="architecture.html#xmodel">XModel</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="architecture.html#shared-state">Shared State</a></li>
<li class="toctree-l2"><a class="reference internal" href="architecture.html#observation">Observation</a><ul>
<li class="toctree-l3"><a class="reference internal" href="architecture.html#logging">Logging</a></li>
<li class="toctree-l3"><a class="reference internal" href="architecture.html#metrics">Metrics</a></li>
<li class="toctree-l3"><a class="reference internal" href="architecture.html#tracing">Tracing</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="aks.html">AKS</a><ul>
<li class="toctree-l2"><a class="reference internal" href="aks.html#introduction-to-aks">Introduction to AKS</a></li>
<li class="toctree-l2"><a class="reference internal" href="aks.html#using-aks-in-amd-inference-server">Using AKS in AMD Inference Server</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="logging.html">Logs</a><ul>
<li class="toctree-l2"><a class="reference internal" href="logging.html#amd-inference-server-logs">AMD Inference Server Logs</a></li>
<li class="toctree-l2"><a class="reference internal" href="logging.html#drogon-logs">Drogon Logs</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="benchmarking.html">Benchmarking</a><ul>
<li class="toctree-l2"><a class="reference internal" href="benchmarking.html#xmodel-benchmarking">XModel Benchmarking</a></li>
<li class="toctree-l2"><a class="reference internal" href="benchmarking.html#kernel-simulation">Kernel Simulation</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="metrics.html">Metrics</a><ul>
<li class="toctree-l2"><a class="reference internal" href="metrics.html#quickstart">Quickstart</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="tracing.html">Tracing</a><ul>
<li class="toctree-l2"><a class="reference internal" href="tracing.html#quickstart">Quickstart</a></li>
</ul>
</li>
</ul>
<p class="caption" role="heading"><span class="caption-text">About</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="contributing.html">Contributing</a><ul>
<li class="toctree-l2"><a class="reference internal" href="contributing.html#ways-to-contribute">Ways to contribute</a><ul>
<li class="toctree-l3"><a class="reference internal" href="contributing.html#idea-generation">Idea generation</a></li>
<li class="toctree-l3"><a class="reference internal" href="contributing.html#raise-issues">Raise issues</a></li>
<li class="toctree-l3"><a class="reference internal" href="contributing.html#triage">Triage</a></li>
<li class="toctree-l3"><a class="reference internal" href="contributing.html#raise-pull-requests">Raise pull requests</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="contributing.html#style-guide">Style guide</a><ul>
<li class="toctree-l3"><a class="reference internal" href="contributing.html#documentation">Documentation</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="dependencies.html">Dependencies</a><ul>
<li class="toctree-l2"><a class="reference internal" href="dependencies.html#docker-image">Docker Image</a><ul>
<li class="toctree-l3"><a class="reference internal" href="dependencies.html#base-image">Base Image</a></li>
<li class="toctree-l3"><a class="reference internal" href="dependencies.html#ubuntu-focal-repositories">Ubuntu Focal Repositories</a></li>
<li class="toctree-l3"><a class="reference internal" href="dependencies.html#ubuntu-ppas">Ubuntu PPAs</a></li>
<li class="toctree-l3"><a class="reference internal" href="dependencies.html#pypi">PyPI</a></li>
<li class="toctree-l3"><a class="reference internal" href="dependencies.html#github">Github</a></li>
<li class="toctree-l3"><a class="reference internal" href="dependencies.html#others">Others</a></li>
<li class="toctree-l3"><a class="reference internal" href="dependencies.html#xilinx">Xilinx</a></li>
<li class="toctree-l3"><a class="reference internal" href="dependencies.html#amd">AMD</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="dependencies.html#included">Included</a></li>
<li class="toctree-l2"><a class="reference internal" href="dependencies.html#downloaded-files">Downloaded Files</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="changelog.html">Changelog</a><ul>
<li class="toctree-l2"><a class="reference internal" href="changelog.html#unreleased">Unreleased</a><ul>
<li class="toctree-l3"><a class="reference internal" href="changelog.html#added">Added</a></li>
<li class="toctree-l3"><a class="reference internal" href="changelog.html#changed">Changed</a></li>
<li class="toctree-l3"><a class="reference internal" href="changelog.html#deprecated">Deprecated</a></li>
<li class="toctree-l3"><a class="reference internal" href="changelog.html#removed">Removed</a></li>
<li class="toctree-l3"><a class="reference internal" href="changelog.html#fixed">Fixed</a></li>
<li class="toctree-l3"><a class="reference internal" href="changelog.html#security">Security</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="changelog.html#id2">0.4.0 - 2023-09-07</a><ul>
<li class="toctree-l3"><a class="reference internal" href="changelog.html#id3">Added</a></li>
<li class="toctree-l3"><a class="reference internal" href="changelog.html#id4">Changed</a></li>
<li class="toctree-l3"><a class="reference internal" href="changelog.html#id5">Deprecated</a></li>
<li class="toctree-l3"><a class="reference internal" href="changelog.html#id6">Removed</a></li>
<li class="toctree-l3"><a class="reference internal" href="changelog.html#id7">Fixed</a></li>
<li class="toctree-l3"><a class="reference internal" href="changelog.html#id8">Security</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="changelog.html#id9">0.3.0 - 2023-02-01</a><ul>
<li class="toctree-l3"><a class="reference internal" href="changelog.html#id10">Added</a></li>
<li class="toctree-l3"><a class="reference internal" href="changelog.html#id11">Changed</a></li>
<li class="toctree-l3"><a class="reference internal" href="changelog.html#id12">Deprecated</a></li>
<li class="toctree-l3"><a class="reference internal" href="changelog.html#id13">Removed</a></li>
<li class="toctree-l3"><a class="reference internal" href="changelog.html#id14">Fixed</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="changelog.html#id15">0.2.0 - 2022-08-05</a><ul>
<li class="toctree-l3"><a class="reference internal" href="changelog.html#id16">Added</a></li>
<li class="toctree-l3"><a class="reference internal" href="changelog.html#id17">Changed</a></li>
<li class="toctree-l3"><a class="reference internal" href="changelog.html#id18">Fixed</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="changelog.html#id19">0.1.0 - 2022-02-08</a><ul>
<li class="toctree-l3"><a class="reference internal" href="changelog.html#id20">Added</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="roadmap.html">Roadmap</a><ul>
<li class="toctree-l2"><a class="reference internal" href="roadmap.html#id1">2022</a><ul>
<li class="toctree-l3"><a class="reference internal" href="roadmap.html#q1">2022 Q1</a></li>
<li class="toctree-l3"><a class="reference internal" href="roadmap.html#q2">2022 Q2</a></li>
<li class="toctree-l3"><a class="reference internal" href="roadmap.html#q3">2022 Q3</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="roadmap.html#id2">2023</a><ul>
<li class="toctree-l3"><a class="reference internal" href="roadmap.html#id3">2023 Q1</a></li>
<li class="toctree-l3"><a class="reference internal" href="roadmap.html#id4">2023 Q2</a></li>
<li class="toctree-l3"><a class="reference internal" href="roadmap.html#id5">2023 Q3</a></li>
<li class="toctree-l3"><a class="reference internal" href="roadmap.html#q4">2023 Q4</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="roadmap.html#future">Future</a></li>
</ul>
</li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Libraries and API</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="amdinfer_script.html">amdinfer Script</a><ul>
<li class="toctree-l2"><a class="reference internal" href="amdinfer_script.html#commands">Commands</a></li>
<li class="toctree-l2"><a class="reference internal" href="amdinfer_script.html#options">Options</a></li>
<li class="toctree-l2"><a class="reference internal" href="amdinfer_script.html#Sub-commands">Sub-commands</a><ul>
<li class="toctree-l3"><a class="reference internal" href="amdinfer_script.html#attach">attach</a></li>
<li class="toctree-l3"><a class="reference internal" href="amdinfer_script.html#benchmark">benchmark</a></li>
<li class="toctree-l3"><a class="reference internal" href="amdinfer_script.html#build">build</a></li>
<li class="toctree-l3"><a class="reference internal" href="amdinfer_script.html#clean">clean</a></li>
<li class="toctree-l3"><a class="reference internal" href="amdinfer_script.html#dockerize">dockerize</a></li>
<li class="toctree-l3"><a class="reference internal" href="amdinfer_script.html#get">get</a></li>
<li class="toctree-l3"><a class="reference internal" href="amdinfer_script.html#install">install</a></li>
<li class="toctree-l3"><a class="reference internal" href="amdinfer_script.html#list">list</a></li>
<li class="toctree-l3"><a class="reference internal" href="amdinfer_script.html#make">make</a></li>
<li class="toctree-l3"><a class="reference internal" href="amdinfer_script.html#run">run</a></li>
<li class="toctree-l3"><a class="reference internal" href="amdinfer_script.html#start">start</a></li>
<li class="toctree-l3"><a class="reference internal" href="amdinfer_script.html#test">test</a></li>
<li class="toctree-l3"><a class="reference internal" href="amdinfer_script.html#up">up</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="cpp_user_api.html">C++</a><ul>
<li class="toctree-l2"><a class="reference internal" href="cpp_user_api.html#clients">Clients</a><ul>
<li class="toctree-l3"><a class="reference internal" href="cpp_user_api.html#grpc">gRPC</a></li>
<li class="toctree-l3"><a class="reference internal" href="cpp_user_api.html#http">HTTP</a></li>
<li class="toctree-l3"><a class="reference internal" href="cpp_user_api.html#native">Native</a></li>
<li class="toctree-l3"><a class="reference internal" href="cpp_user_api.html#websocket">WebSocket</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="cpp_user_api.html#core">Core</a><ul>
<li class="toctree-l3"><a class="reference internal" href="cpp_user_api.html#datatype">DataType</a></li>
<li class="toctree-l3"><a class="reference internal" href="cpp_user_api.html#exceptions">Exceptions</a></li>
<li class="toctree-l3"><a class="reference internal" href="cpp_user_api.html#prediction">Prediction</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="cpp_user_api.html#servers">Servers</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="python.html">Python</a><ul>
<li class="toctree-l2"><a class="reference internal" href="python.html#install-the-python-library">Install the Python library</a><ul>
<li class="toctree-l3"><a class="reference internal" href="python.html#build-wheels">Build wheels</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="python.html#module-amdinfer">API</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="rest.html">REST Endpoints</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu"  style="background: black" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="index.html">AMD Inference Server</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="index.html" class="icon icon-home"></a> &raquo;</li>
      <li>Client API</li>
      <li class="wy-breadcrumbs-aside">
            <a href="_sources/client_api.rst.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section id="client-api">
<h1>Client API<a class="headerlink" href="#client-api" title="Permalink to this headline">¶</a></h1>
<p>The client API enables users to interact with the inference server.
This page highlights some of the important methods that you can use.</p>
<section id="include-the-api">
<h2>Include the API<a class="headerlink" href="#include-the-api" title="Permalink to this headline">¶</a></h2>
<p>After installing the client API, you can include it in your code with a single line:</p>
<div class="sphinx-tabs docutils container">
<div aria-label="Tabbed content" class="closeable" role="tablist"><button aria-controls="panel-0-Qysr" aria-selected="true" class="sphinx-tabs-tab code-tab group-tab" id="tab-0-Qysr" name="Qysr" role="tab" tabindex="0">C++</button><button aria-controls="panel-0-UHl0aG9u" aria-selected="false" class="sphinx-tabs-tab code-tab group-tab" id="tab-0-UHl0aG9u" name="UHl0aG9u" role="tab" tabindex="-1">Python</button></div><div aria-labelledby="tab-0-Qysr" class="sphinx-tabs-panel code-tab group-tab" id="panel-0-Qysr" name="Qysr" role="tabpanel" tabindex="0"><div class="highlight-c++ notranslate"><div class="highlight"><pre><span></span><span class="cp">#include</span><span class="w"> </span><span class="cpf">&quot;amdinfer/amdinfer.hpp&quot;</span>
</pre></div>
</div>
</div><div aria-labelledby="tab-0-UHl0aG9u" class="sphinx-tabs-panel code-tab group-tab" hidden="true" id="panel-0-UHl0aG9u" name="UHl0aG9u" role="tabpanel" tabindex="0"><div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">amdinfer</span>
</pre></div>
</div>
</div></div>
</section>
<section id="create-a-client-object">
<h2>Create a client object<a class="headerlink" href="#create-a-client-object" title="Permalink to this headline">¶</a></h2>
<p>A client object enables you to talk to the server using the protocol of your choice.
The inference server supports the following protocols which you can use independently.</p>
<div class="sphinx-tabs docutils container">
<div aria-label="Tabbed content" class="closeable" role="tablist"><button aria-controls="panel-1-Qysr" aria-selected="true" class="sphinx-tabs-tab code-tab group-tab" id="tab-1-Qysr" name="Qysr" role="tab" tabindex="0">C++</button><button aria-controls="panel-1-UHl0aG9u" aria-selected="false" class="sphinx-tabs-tab code-tab group-tab" id="tab-1-UHl0aG9u" name="UHl0aG9u" role="tab" tabindex="-1">Python</button></div><div aria-labelledby="tab-1-Qysr" class="sphinx-tabs-panel code-tab group-tab" id="panel-1-Qysr" name="Qysr" role="tabpanel" tabindex="0"><div class="highlight-c++ notranslate"><div class="highlight"><pre><span></span><span class="c1">// native - the server must be started in the same process</span>
<span class="n">amdinfer</span><span class="o">::</span><span class="n">Server</span><span class="w"> </span><span class="n">server</span><span class="p">;</span>
<span class="n">amdinfer</span><span class="o">::</span><span class="n">NativeClient</span><span class="w"> </span><span class="nf">client</span><span class="p">(</span><span class="o">&amp;</span><span class="n">server</span><span class="p">);</span>

<span class="c1">// HTTP/REST</span>
<span class="n">amdinfer</span><span class="o">::</span><span class="n">HttpClient</span><span class="w"> </span><span class="n">client</span><span class="p">{</span><span class="s">&quot;http://127.0.0.1:8998&quot;</span><span class="p">};</span>

<span class="c1">// gRPC</span>
<span class="n">amdinfer</span><span class="o">::</span><span class="n">GrpcClient</span><span class="w"> </span><span class="n">client</span><span class="p">{</span><span class="s">&quot;127.0.0.1:50051&quot;</span><span class="p">};</span>
</pre></div>
</div>
</div><div aria-labelledby="tab-1-UHl0aG9u" class="sphinx-tabs-panel code-tab group-tab" hidden="true" id="panel-1-UHl0aG9u" name="UHl0aG9u" role="tabpanel" tabindex="0"><div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># native - the server must be started in the same script</span>
<span class="n">server</span> <span class="o">=</span> <span class="n">amdinfer</span><span class="o">.</span><span class="n">Server</span><span class="p">()</span>
<span class="n">client</span> <span class="o">=</span> <span class="n">amdinfer</span><span class="o">.</span><span class="n">NativeClient</span><span class="p">(</span><span class="n">server</span><span class="p">)</span>

<span class="c1"># HTTP/REST</span>
<span class="n">client</span> <span class="o">=</span> <span class="n">amdinfer</span><span class="o">.</span><span class="n">HttpClient</span><span class="p">(</span><span class="s2">&quot;http://127.0.0.1:8998&quot;</span><span class="p">)</span>

<span class="c1"># gRPC</span>
<span class="n">client</span> <span class="o">=</span> <span class="n">amdinfer</span><span class="o">.</span><span class="n">GrpcClient</span><span class="p">(</span><span class="s2">&quot;127.0.0.1:50051&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div></div>
<p>All clients have the same interface after the initial construction so you can use any client in the next set of steps.</p>
</section>
<section id="server-status">
<h2>Server status<a class="headerlink" href="#server-status" title="Permalink to this headline">¶</a></h2>
<p>You can check the state and health of the server using the following methods of all client objects: <code class="docutils literal notranslate"><span class="pre">serverMetadata()</span></code>, <code class="docutils literal notranslate"><span class="pre">serverLive()</span></code>, <code class="docutils literal notranslate"><span class="pre">serverReady()</span></code>, <code class="docutils literal notranslate"><span class="pre">modelReady()</span></code>, <code class="docutils literal notranslate"><span class="pre">modelMetadata()</span></code> and <code class="docutils literal notranslate"><span class="pre">hasHardware()</span></code>.</p>
<p>These base methods of client objects enable the following helper functions that take a client object as the first argument: <code class="docutils literal notranslate"><span class="pre">serverHasExtension()</span></code>, <code class="docutils literal notranslate"><span class="pre">waitUntilServerReady()</span></code>, <code class="docutils literal notranslate"><span class="pre">waitUntilModelReady()</span></code> and <code class="docutils literal notranslate"><span class="pre">waitUntilModelNotReady()</span></code>.</p>
<p>You can see more information about these functions in the API documentation for <a class="reference internal" href="cpp_user_api.html#c"><span class="std std-ref">C++</span></a> and <a class="reference internal" href="python.html#python-api"><span class="std std-ref">Python</span></a>.</p>
</section>
<section id="loading-a-backend">
<h2>Loading a backend<a class="headerlink" href="#loading-a-backend" title="Permalink to this headline">¶</a></h2>
<p>If the server you are using is not already ready to serve incoming inference requests for your model, you may need to load a <a class="reference internal" href="backends.html#backends"><span class="std std-ref">backend</span></a> to serve your model first.</p>
<p>Client objects provide two methods to load backends: <code class="docutils literal notranslate"><span class="pre">modelLoad()</span></code> and <code class="docutils literal notranslate"><span class="pre">workerLoad()</span></code>.
The former loads the named model from the <a class="reference internal" href="model_repository.html#model-repository"><span class="std std-ref">model repository</span></a> while the latter is a lower-level method to directly load a backend with a path to a particular model file.
The path to the model file, and other load-time parameters, can be passed to the server with these methods.
Each backend defines its own load-time parameters so check the documentation for the backend you want to use.</p>
<p>When you load a backend, you get an <em>endpoint</em> that you can use to make further requests to.
For <code class="docutils literal notranslate"><span class="pre">modelLoad()</span></code>, the endpoint is the same name as the model you pass to the method.
For <code class="docutils literal notranslate"><span class="pre">workerLoad()</span></code>, the server will assign it an endpoint and return it from the call to <code class="docutils literal notranslate"><span class="pre">workerLoad()</span></code>.</p>
<p>You can also load <a class="reference internal" href="ensembles.html#ensembles"><span class="std std-ref">ensembles</span></a> with <code class="docutils literal notranslate"><span class="pre">loadEnsemble()</span></code>.</p>
</section>
<section id="making-an-inference-request">
<h2>Making an inference request<a class="headerlink" href="#making-an-inference-request" title="Permalink to this headline">¶</a></h2>
<p>A basic inference request to the server consists of a list of input tensors.
You can construct a request with something like this:</p>
<div class="sphinx-tabs docutils container">
<div aria-label="Tabbed content" class="closeable" role="tablist"><button aria-controls="panel-2-Qysr" aria-selected="true" class="sphinx-tabs-tab code-tab group-tab" id="tab-2-Qysr" name="Qysr" role="tab" tabindex="0">C++</button><button aria-controls="panel-2-UHl0aG9u" aria-selected="false" class="sphinx-tabs-tab code-tab group-tab" id="tab-2-UHl0aG9u" name="UHl0aG9u" role="tab" tabindex="-1">Python</button></div><div aria-labelledby="tab-2-Qysr" class="sphinx-tabs-panel code-tab group-tab" id="panel-2-Qysr" name="Qysr" role="tabpanel" tabindex="0"><div class="highlight-c++ notranslate"><div class="highlight"><pre><span></span><span class="n">amdinfer</span><span class="o">::</span><span class="n">InferenceRequest</span><span class="w"> </span><span class="n">request</span><span class="p">;</span>

<span class="c1">// void* data = ...;</span>
<span class="n">amdinfer</span><span class="o">::</span><span class="n">InferenceRequestInput</span><span class="w"> </span><span class="n">input_tensor</span><span class="p">{</span>
<span class="w">    </span><span class="n">data</span><span class="p">,</span><span class="w"> </span><span class="p">{</span><span class="mi">224</span><span class="p">,</span><span class="w"> </span><span class="mi">224</span><span class="p">,</span><span class="w"> </span><span class="mi">3</span><span class="p">},</span><span class="w"> </span><span class="n">amdinfer</span><span class="o">::</span><span class="n">DataType</span><span class="o">::</span><span class="n">FP32</span><span class="p">,</span><span class="w"> </span><span class="s">&quot;input&quot;</span>
<span class="p">};</span>
<span class="n">request</span><span class="p">.</span><span class="n">addInputTensor</span><span class="p">(</span><span class="n">input_tensor</span><span class="p">);</span>

<span class="c1">// add other tensors?</span>
</pre></div>
</div>
</div><div aria-labelledby="tab-2-UHl0aG9u" class="sphinx-tabs-panel code-tab group-tab" hidden="true" id="panel-2-UHl0aG9u" name="UHl0aG9u" role="tabpanel" tabindex="0"><div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">request</span> <span class="o">=</span> <span class="n">amdinfer</span><span class="o">.</span><span class="n">InferenceRequest</span><span class="p">()</span>

<span class="n">input_tensor</span> <span class="o">=</span> <span class="n">amdinfer</span><span class="o">.</span><span class="n">InferenceRequestInput</span><span class="p">()</span>
<span class="n">input_tensor</span><span class="o">.</span><span class="n">name</span> <span class="o">=</span> <span class="s2">&quot;input&quot;</span>
<span class="n">input_tensor</span><span class="o">.</span><span class="n">datatype</span> <span class="o">=</span> <span class="n">amdinfer</span><span class="o">.</span><span class="n">DataType</span><span class="o">.</span><span class="n">FP32</span>
<span class="n">input_tensor</span><span class="o">.</span><span class="n">shape</span> <span class="o">=</span> <span class="p">(</span><span class="mi">224</span><span class="p">,</span> <span class="mi">224</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>
<span class="c1"># data could be a list or a numpy array</span>
<span class="n">input_tensor</span><span class="o">.</span><span class="n">setFp32Data</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
<span class="n">request</span><span class="o">.</span><span class="n">addInputTensor</span><span class="p">(</span><span class="n">input_tensor</span><span class="p">)</span>

<span class="c1"># add other tensors?</span>
</pre></div>
</div>
</div></div>
<p>Once you have a request, you can use the client’s <code class="docutils literal notranslate"><span class="pre">modelInfer()</span></code> method:</p>
<div class="sphinx-tabs docutils container">
<div aria-label="Tabbed content" class="closeable" role="tablist"><button aria-controls="panel-3-Qysr" aria-selected="true" class="sphinx-tabs-tab code-tab group-tab" id="tab-3-Qysr" name="Qysr" role="tab" tabindex="0">C++</button><button aria-controls="panel-3-UHl0aG9u" aria-selected="false" class="sphinx-tabs-tab code-tab group-tab" id="tab-3-UHl0aG9u" name="UHl0aG9u" role="tab" tabindex="-1">Python</button></div><div aria-labelledby="tab-3-Qysr" class="sphinx-tabs-panel code-tab group-tab" id="panel-3-Qysr" name="Qysr" role="tabpanel" tabindex="0"><div class="highlight-c++ notranslate"><div class="highlight"><pre><span></span><span class="c1">// endpoint is a string from loading a backend or provided to you</span>
<span class="k">auto</span><span class="w"> </span><span class="n">response</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">client</span><span class="p">.</span><span class="n">modelInfer</span><span class="p">(</span><span class="n">endpoint</span><span class="p">,</span><span class="w"> </span><span class="n">request</span><span class="p">);</span>
</pre></div>
</div>
</div><div aria-labelledby="tab-3-UHl0aG9u" class="sphinx-tabs-panel code-tab group-tab" hidden="true" id="panel-3-UHl0aG9u" name="UHl0aG9u" role="tabpanel" tabindex="0"><div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># endpoint is a string from loading a backend or provided to you</span>
<span class="n">response</span> <span class="o">=</span> <span class="n">client</span><span class="o">.</span><span class="n">modelInfer</span><span class="p">(</span><span class="n">endpoint</span><span class="p">,</span> <span class="n">request</span><span class="p">)</span>
</pre></div>
</div>
</div></div>
<p>The client API also provides other methods for making inferences such as <code class="docutils literal notranslate"><span class="pre">modelInferAsync()</span></code> and <code class="docutils literal notranslate"><span class="pre">inferAsyncOrdered()</span></code>.
You can see more information about the available methods in the API documentation for <a class="reference internal" href="cpp_user_api.html#c"><span class="std std-ref">C++</span></a> and <a class="reference internal" href="python.html#python-api"><span class="std std-ref">Python</span></a>.</p>
</section>
<section id="parsing-the-response">
<h2>Parsing the response<a class="headerlink" href="#parsing-the-response" title="Permalink to this headline">¶</a></h2>
<p>The basic response from the inference server consists of an array of output tensors.</p>
<div class="sphinx-tabs docutils container">
<div aria-label="Tabbed content" class="closeable" role="tablist"><button aria-controls="panel-4-Qysr" aria-selected="true" class="sphinx-tabs-tab code-tab group-tab" id="tab-4-Qysr" name="Qysr" role="tab" tabindex="0">C++</button><button aria-controls="panel-4-UHl0aG9u" aria-selected="false" class="sphinx-tabs-tab code-tab group-tab" id="tab-4-UHl0aG9u" name="UHl0aG9u" role="tab" tabindex="-1">Python</button></div><div aria-labelledby="tab-4-Qysr" class="sphinx-tabs-panel code-tab group-tab" id="panel-4-Qysr" name="Qysr" role="tabpanel" tabindex="0"><div class="highlight-c++ notranslate"><div class="highlight"><pre><span></span><span class="k">auto</span><span class="w"> </span><span class="n">response</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">client</span><span class="p">.</span><span class="n">modelInfer</span><span class="p">(</span><span class="n">endpoint</span><span class="p">,</span><span class="w"> </span><span class="n">request</span><span class="p">);</span>
<span class="k">if</span><span class="p">(</span><span class="o">!</span><span class="n">response</span><span class="p">.</span><span class="n">isError</span><span class="p">()){</span>
<span class="w">    </span><span class="k">auto</span><span class="w"> </span><span class="n">output_tensors</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">response</span><span class="p">.</span><span class="n">getOutputs</span><span class="p">();</span>
<span class="w">    </span><span class="k">for</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="k">auto</span><span class="o">&amp;</span><span class="w"> </span><span class="n">output_tensor</span><span class="w"> </span><span class="o">:</span><span class="w"> </span><span class="n">output_tensors</span><span class="p">){</span>
<span class="w">        </span><span class="c1">// you can use methods to get the shape, datatype and name and data</span>
<span class="w">    </span><span class="p">}</span>
<span class="p">}</span>
</pre></div>
</div>
</div><div aria-labelledby="tab-4-UHl0aG9u" class="sphinx-tabs-panel code-tab group-tab" hidden="true" id="panel-4-UHl0aG9u" name="UHl0aG9u" role="tabpanel" tabindex="0"><div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">response</span> <span class="o">=</span> <span class="n">client</span><span class="o">.</span><span class="n">modelInfer</span><span class="p">(</span><span class="n">endpoint</span><span class="p">,</span> <span class="n">request</span><span class="p">)</span>
<span class="k">if</span> <span class="ow">not</span> <span class="n">response</span><span class="o">.</span><span class="n">isError</span><span class="p">():</span>
    <span class="n">output_tensors</span> <span class="o">=</span> <span class="n">response</span><span class="o">.</span><span class="n">getOutputs</span><span class="p">()</span>
    <span class="k">for</span> <span class="n">output_tensor</span> <span class="ow">in</span> <span class="n">output_tensors</span><span class="p">:</span>
        <span class="c1"># you can use methods to get the shape, datatype and name and data</span>
</pre></div>
</div>
</div></div>
<p>You can see more information about the available methods in the API documentation for <a class="reference internal" href="cpp_user_api.html#c"><span class="std std-ref">C++</span></a> and <a class="reference internal" href="python.html#python-api"><span class="std std-ref">Python</span></a>.</p>
</section>
<section id="next-steps">
<h2>Next steps<a class="headerlink" href="#next-steps" title="Permalink to this headline">¶</a></h2>
<p>Take a look at the examples to see these APIs used in practice.</p>
</section>
</section>


           </div>
          </div>
          	  
				  <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="deployment.html" class="btn btn-neutral float-left" title="Deployment" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="kserve.html" class="btn btn-neutral float-right" title="KServe" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2022 Advanced Micro Devices, Inc..
      <span class="lastupdated">Last updated on September 07, 2023.
      </span></p>
  </div>



										<div class="aem-Grid aem-Grid--16">
											<div class="aem-GridColumn aem-GridColumn--xxxlarge--none aem-GridColumn--xsmall--16 aem-GridColumn--offset--xsmall--0 aem-GridColumn--xlarge--none aem-GridColumn--xxlarge--none aem-GridColumn--default--none aem-GridColumn--offset--large--1 aem-GridColumn--xlarge--12 aem-GridColumn--offset--default--0 aem-GridColumn--xxlarge--10 aem-GridColumn--offset--xlarge--2 aem-GridColumn--offset--xxlarge--3 aem-GridColumn--offset--xxxlarge--4 aem-GridColumn--xsmall--none aem-GridColumn--large--none aem-GridColumn aem-GridColumn--large--14 aem-GridColumn--xxxlarge--8 aem-GridColumn--default--16">
												<div class="container-fluid sub-footer">

													                    <div class="row">
                        <div class="col-xs-24">
                          <p><a target="_blank" href="https://www.amd.com/en/corporate/copyright">Terms and Conditions</a> | <a target="_blank" href="https://www.amd.com/en/corporate/privacy">Privacy</a> | <a target="_blank" href="https://www.amd.com/en/corporate/cookies">Cookie Policy</a> | <a target="_blank" href="https://www.amd.com/en/corporate/trademarks">Trademarks</a> | <a target="_blank" href="https://www.amd.com/system/files/documents/statement-human-trafficking-forced-labor.pdf">Statement on Forced Labor</a> | <a target="_blank" href="https://www.amd.com/en/corporate/competition">Fair and Open Competition</a> | <a target="_blank" href="https://www.amd.com/system/files/documents/amd-uk-tax-strategy.pdf">UK Tax Strategy</a> | <a target="_blank" href="https://docs.xilinx.com/v/u/9x6YvZKuWyhJId7y7RQQKA">Inclusive Terminology</a> | <a href="#cookiessettings" class="ot-sdk-show-settings">Cookies Settings</a></p>
                        </div>
                    </div>
												</div>
											</div>
										</div>
										
</br>


  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  

  <div class="rst-versions" data-toggle="rst-versions" role="note" aria-label="versions">
    <span class="rst-current-version" data-toggle="rst-current-version">
      <span class="fa fa-book"> Read the Docs</span>
      v: 0.4.0
      <span class="fa fa-caret-down"></span>
    </span>
    <div class="rst-other-versions">
      
      <dl>
        <dt>Languages</dt>
        
           <strong> 
          <dd><a href="/inference-server/0.4.0/">en</a></dd>
           </strong> 
        
      </dl>
      
      
      <dl>
        <dt>Versions</dt>
        
          
          <dd><a href="/inference-server/0.1.0/">0.1.0</a></dd>
          
        
          
          <dd><a href="/inference-server/0.2.0/">0.2.0</a></dd>
          
        
          
          <dd><a href="/inference-server/0.3.0/">0.3.0</a></dd>
          
        
           <strong> 
          <dd><a href="/inference-server/0.4.0/">0.4.0</a></dd>
           </strong> 
        
          
          <dd><a href="/inference-server/main/">main</a></dd>
          
        
      </dl>
      
      
       
    </div>
  </div>
<script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(false);
      });
  </script>
 <script type="text/javascript">
    $(document).ready(function() {
        $(".toggle > *").hide();
        $(".toggle .header").show();
        $(".toggle .header").click(function() {
            $(this).parent().children().not(".header").toggle(400);
            $(this).parent().children(".header").toggleClass("open");
        })
    });
</script>


</body>
</html>