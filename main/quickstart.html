<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  
<!-- OneTrust Cookies Consent Notice start for xilinx.github.io -->

<script src="https://cdn.cookielaw.org/scripttemplates/otSDKStub.js" data-document-language="true" type="text/javascript" charset="UTF-8" data-domain-script="03af8d57-0a04-47a6-8f10-322fa00d8fc7" ></script>
<script type="text/javascript">
function OptanonWrapper() { }
</script>
<!-- OneTrust Cookies Consent Notice end for xilinx.github.io -->
<!-- Google Tag Manager -->
<script type="text/plain" class="optanon-category-C0002">(function(w,d,s,l,i){w[l]=w[l]||[];w[l].push({'gtm.start':
new Date().getTime(),event:'gtm.js'});var f=d.getElementsByTagName(s)[0],
j=d.createElement(s),dl=l!='dataLayer'?'&l='+l:'';j.async=true;j.src=
'//www.googletagmanager.com/gtm.js?id='+i+dl;f.parentNode.insertBefore(j,f);
})(window,document,'script','dataLayer','GTM-5RHQV7');</script>
<!-- End Google Tag Manager -->
  <title>Quickstart &mdash; AMD Inference Server v0.3.0 documentation</title>
      <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
      <link rel="stylesheet" href="_static/css/theme.css" type="text/css" />
      <link rel="stylesheet" href="_static/copybutton.css" type="text/css" />
      <link rel="stylesheet" href="_static/bootstrap-treeview/bootstrap-treeview.min.css" type="text/css" />
  <!--[if lt IE 9]>
    <script src="_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script data-url_root="./" id="documentation_options" src="_static/documentation_options.js"></script>
        <script src="_static/jquery.js"></script>
        <script src="_static/underscore.js"></script>
        <script src="_static/doctools.js"></script>
        <script src="_static/clipboard.min.js"></script>
        <script src="_static/copybutton.js"></script>
        <script src="_static/bootstrap-treeview/bootstrap-treeview.min.js"></script>
    <script src="_static/js/theme.js"></script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="Hello World - Python" href="hello_world_echo.html" />
    <link rel="prev" title="AMD Inference Server" href="index.html" /> 
</head>

<body class="wy-body-for-nav">

<!-- Google Tag Manager -->
<noscript><iframe src="//www.googletagmanager.com/ns.html?id=GTM-5RHQV7" height="0" width="0" style="display:none;visibility:hidden" class="optanon-category-C0002"></iframe></noscript>
<!-- End Google Tag Manager --> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search">
            <a href="index.html" class="icon icon-home"> AMD Inference Server
          </a>
              <div class="version">
                main
              </div>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <ul>
<li class="toctree-l1"><a class="reference internal" href="index.html">AMD Inference Server</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Getting Started</span></p>
<ul class="current">
<li class="toctree-l1 current"><a class="current reference internal" href="#">Quickstart</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#deployment">Deployment</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#build-or-get-the-docker-image">Build or get the Docker image</a></li>
<li class="toctree-l3"><a class="reference internal" href="#launch-the-server">Launch the server</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#development">Development</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#id2">Build or get the Docker image</a></li>
<li class="toctree-l3"><a class="reference internal" href="#compiling-the-amd-inference-server">Compiling the AMD Inference Server</a></li>
<li class="toctree-l3"><a class="reference internal" href="#getting-test-artifacts">Getting test artifacts</a></li>
<li class="toctree-l3"><a class="reference internal" href="#running-the-amd-inference-server">Running the AMD Inference Server</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="hello_world_echo.html">Hello World - Python</a></li>
<li class="toctree-l1"><a class="reference internal" href="example_resnet50_cpp.html">Running ResNet50 - C++</a></li>
<li class="toctree-l1"><a class="reference internal" href="example_resnet50_python.html">Running ResNet50 - Python</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Using AMD Inference Server</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="aks.html">AKS</a></li>
<li class="toctree-l1"><a class="reference internal" href="logging.html">Logs</a></li>
<li class="toctree-l1"><a class="reference internal" href="benchmarking.html">Benchmarking</a></li>
<li class="toctree-l1"><a class="reference internal" href="metrics.html">Metrics</a></li>
<li class="toctree-l1"><a class="reference internal" href="tracing.html">Tracing</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Platforms</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="zendnn.html">CPUs - ZenDNN</a></li>
<li class="toctree-l1"><a class="reference internal" href="migraphx.html">GPUs - MIGraphX</a></li>
<li class="toctree-l1"><a class="reference internal" href="vitis_ai.html">FPGAs - Vitis AI</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Deployment</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="docker.html">Docker</a></li>
<li class="toctree-l1"><a class="reference internal" href="kserve.html">KServe</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Getting Performance</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="performance_factors.html">Factors</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">User API libraries</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="rest.html">REST Endpoints</a></li>
<li class="toctree-l1"><a class="reference internal" href="cpp_user_api.html">C++</a></li>
<li class="toctree-l1"><a class="reference internal" href="python.html">Python</a></li>
<li class="toctree-l1"><a class="reference internal" href="cli.html">Command-Line Interface</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Developers</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="architecture.html">Architecture</a></li>
<li class="toctree-l1"><a class="reference internal" href="contributing.html">Contributing</a></li>
<li class="toctree-l1"><a class="reference internal" href="cpp_api/cpp_root.html">Code Documentation</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">About</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="roadmap.html">Roadmap</a></li>
<li class="toctree-l1"><a class="reference internal" href="changelog.html">Changelog</a></li>
<li class="toctree-l1"><a class="reference internal" href="glossary.html">Glossary</a></li>
<li class="toctree-l1"><a class="reference internal" href="dependencies.html">Dependencies</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="index.html">AMD Inference Server</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="index.html" class="icon icon-home"></a> &raquo;</li>
      <li>Quickstart</li>
      <li class="wy-breadcrumbs-aside">
            <a href="_sources/quickstart.rst.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section id="quickstart">
<span id="id1"></span><h1>Quickstart<a class="headerlink" href="#quickstart" title="Permalink to this headline">¶</a></h1>
<p>The easiest way to use the AMD Inference Server is to run it inside a <a class="reference external" href="https://docs.docker.com/get-docker/">Docker container</a>.
There are two modes of operation: development and deployment.
If you are just interested in deploying the server to serve inferences, then consider the deployment instructions.
For testing, debugging, and experimentation, you will need to follow the development instructions.</p>
<p>Ensure that you set up your host appropriately depending on which platform(s) you are using.
The helper script used for many of the commands here is <code class="file docutils literal notranslate"><span class="pre">amdinfer</span></code>: a Python script with many helpful options.
The most up-to-date documentation for this script can be seen with <a class="reference internal" href="cli.html#command-line-interface"><span class="std std-ref">online</span></a> or on the terminal with <code class="xref std std-option docutils literal notranslate"><span class="pre">--help</span></code>.
You can also use <code class="xref std std-option docutils literal notranslate"><span class="pre">--dry-run</span></code> before any command to see the underlying commands the script is running.</p>
<section id="deployment">
<h2>Deployment<a class="headerlink" href="#deployment" title="Permalink to this headline">¶</a></h2>
<p>For deployment, the container for the AMD Inference server only contains the runtime dependencies of the server to minimize image size.
The deployment container, also referred to as the production container, contains a precompiled binary for the server that automatically starts when the container starts.</p>
<section id="build-or-get-the-docker-image">
<h3>Build or get the Docker image<a class="headerlink" href="#build-or-get-the-docker-image" title="Permalink to this headline">¶</a></h3>
<p>You can use <code class="docutils literal notranslate"><span class="pre">docker</span> <span class="pre">pull</span></code> to get the production container from a Docker registry if it’s already built.</p>
<p>To build from source, you will need Docker 18.09 or newer because you need to enable <a class="reference external" href="https://docs.docker.com/build/">BuildKit</a> to build the image.
Look at the instructions for <a class="reference internal" href="docker.html#build-the-production-docker-image"><span class="std std-ref">building the production container</span></a> for more information.</p>
</section>
<section id="launch-the-server">
<h3>Launch the server<a class="headerlink" href="#launch-the-server" title="Permalink to this headline">¶</a></h3>
<p>Your chosen deployment method determines how to start the server.</p>
<p>If you want to launch it as a bare Docker container, follow the <a class="reference internal" href="docker.html#prepare-the-image-for-docker-deployment"><span class="std std-ref">Docker instructions</span></a>.
This has the fewest external dependencies but requires more manual work to set up the image.</p>
<p>If you want to use the AMD Inference Server with <a class="reference external" href="https://kserve.github.io/website/master/">KServe</a>, follow the <a class="reference internal" href="kserve.html#start-an-inference-service"><span class="std std-ref">KServe instructions</span></a>.
KServe is an open-source project for model serving in production on Kubernetes.
Using this deployment method requires a working Kubernetes cluster with KServe installed.</p>
</section>
</section>
<section id="development">
<h2>Development<a class="headerlink" href="#development" title="Permalink to this headline">¶</a></h2>
<p>For development, the container for the AMD Inference server contains the build-time dependencies needed to compile and test the inference server.
However, the development container, also referred to as the dev container, does not contain the inference server source code.
The expected workflow is that you mount the source code into the container.</p>
<p>For development, your host needs Git, Python3, and <a class="reference external" href="https://docs.docker.com/get-docker/">Docker</a>.
Some tests require <a class="reference external" href="https://docs.docker.com/compose/install/">Docker-Compose</a> as well.</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>git clone https://github.com/Xilinx/inference-server.git
</pre></div>
</div>
<p>Tests and examples need assets like images and videos to run.
Some of these files are stored in <a class="reference external" href="https://git-lfs.github.com/">Git LFS</a>.
Depending on your host, these files may be automatically downloaded with the <code class="docutils literal notranslate"><span class="pre">git</span> <span class="pre">clone</span></code>.
If some of the files in <code class="docutils literal notranslate"><span class="pre">tests/assets</span></code> are very small (less than 300 bytes), then you haven’t downloaded these Git LFS artifacts.
From your host or after entering the dev container, use <code class="docutils literal notranslate"><span class="pre">git</span> <span class="pre">lfs</span> <span class="pre">pull</span></code> to get these files.</p>
<section id="id2">
<h3>Build or get the Docker image<a class="headerlink" href="#id2" title="Permalink to this headline">¶</a></h3>
<p>You can use <code class="docutils literal notranslate"><span class="pre">docker</span> <span class="pre">pull</span></code> to get the dev container from a Docker registry if it’s already built.</p>
<p>To build from source, you will need Docker 18.09 or newer because you need to enable <a class="reference external" href="https://docs.docker.com/build/">BuildKit</a> to build the image.
After cloning the repository, enter the directory and run:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">$ </span>python3 docker/generate.py
<span class="gp">$ </span>./amdinfer dockerize &lt;platform flags&gt;
</pre></div>
</div>
<p>The <code class="docutils literal notranslate"><span class="pre">generate.py</span></code> script is used to create a dockerfile in the root directory, which is then used by the <code class="docutils literal notranslate"><span class="pre">dockerize</span></code> command.
Use <code class="docutils literal notranslate"><span class="pre">--help</span></code> to see configurable options for the <code class="docutils literal notranslate"><span class="pre">generate.py</span></code> script.
If you want to enable any platforms, pass the appropriate flags.
Look at the platform-specific documentation for more information about these flags.</p>
<p>By default, this builds the dev image as <code class="docutils literal notranslate"><span class="pre">&lt;username&gt;/amdinfer-dev:latest</span></code>.
After the image is built, run the container:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">$ </span>./amdinfer run --dev
</pre></div>
</div>
<p>This command runs the <code class="docutils literal notranslate"><span class="pre">&lt;username&gt;/amdinfer-dev:latest</span></code> image, which corresponds to the latest local dev image.
The <code class="docutils literal notranslate"><span class="pre">--dev</span></code> preset will mount the working directory into <code class="file docutils literal notranslate"><span class="pre">/workspace/amdinfer/</span></code>, mount some additional directories into the container, expose some ports to the host and pass in any available hardware like FPGAs.
Some options may be overridden on the command-line (use <code class="xref std std-option docutils literal notranslate"><span class="pre">--help</span></code> to see the options).
By default, it will open a Bash shell in this container and show you a splash screen to show that you’ve entered the container.</p>
</section>
<section id="compiling-the-amd-inference-server">
<h3>Compiling the AMD Inference Server<a class="headerlink" href="#compiling-the-amd-inference-server" title="Permalink to this headline">¶</a></h3>
<p>These commands are all run inside the dev container.
Here, <code class="file docutils literal notranslate"><span class="pre">./amdinfer</span></code> is aliased to <strong class="command">amdinfer</strong>.</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">$ </span>amdinfer build
</pre></div>
</div>
<p>The build command builds the <strong class="program">amdinfer-server</strong> executable.
By default, this will be the debug version.
You can pass flags to <code class="docutils literal notranslate"><span class="pre">build</span></code> to control the compile options.</p>
<div class="admonition tip">
<p class="admonition-title">Tip</p>
<p>When starting new containers or switching to different ones after having run build once, you may need to run <code class="docutils literal notranslate"><span class="pre">amdinfer</span> <span class="pre">build</span> <span class="pre">--regen</span> <span class="pre">--clean</span></code> initially.
New containers mount the working directory and so stale artifacts from previous builds may be present.
These two flags delete the CMake cache and do a clean build, respectively.</p>
</div>
<div class="admonition warning">
<p class="admonition-title">Warning</p>
<p>In general, you should not use <code class="docutils literal notranslate"><span class="pre">sudo</span></code> to run <code class="docutils literal notranslate"><span class="pre">amdinfer</span></code> commands.
Some commands create files in your working directory and using <code class="docutils literal notranslate"><span class="pre">sudo</span></code> creates files with mixed permissions in your container and host and will even fail in some cases.</p>
</div>
<p>The <code class="docutils literal notranslate"><span class="pre">build</span></code> will also install the server’s Python library in the dev container.
You can use it from Python in the container after importing it.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">amdinfer</span>
</pre></div>
</div>
</section>
<section id="getting-test-artifacts">
<h3>Getting test artifacts<a class="headerlink" href="#getting-test-artifacts" title="Permalink to this headline">¶</a></h3>
<p>For running tests and certain examples, you need to get models and other files.
Make sure you have <a class="reference external" href="https://git-lfs.github.com/">Git LFS</a> installed.
You can download all files, as shown below with the <code class="docutils literal notranslate"><span class="pre">--all</span></code> flag, or download platform-specific files.
Use <code class="docutils literal notranslate"><span class="pre">--help</span></code> to see the options available.</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">$ </span>git lfs pull
<span class="gp">$ </span>amdinfer get --all
</pre></div>
</div>
<p>You must abide by the license agreements of these files, if you choose to download them.</p>
</section>
<section id="running-the-amd-inference-server">
<h3>Running the AMD Inference Server<a class="headerlink" href="#running-the-amd-inference-server" title="Permalink to this headline">¶</a></h3>
<p>Once the server is built, start the server to begin serving requests.</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="c1"># start the server</span>
amdinfer start

<span class="c1"># this command will block and the server will idle for requests</span>
<span class="c1"># from a new terminal, you can send it requests</span>

<span class="c1"># test that the server is ready. The server returns status 200 OK on success</span>
curl -I http://localhost:8998/v2/health/ready

<span class="c1"># the server can now accept requests over REST/gRPC</span>

<span class="c1"># shutdown the server using Ctrl+C</span>
</pre></div>
</div>
<p>The <a class="reference internal" href="rest.html#rest-endpoints"><span class="std std-ref">REST endpoints</span></a> available to the server are based on <a class="reference external" href="https://github.com/kserve/kserve/blob/master/docs/predict-api/v2/required_api.md">KServe’s v2 specification</a>.
While using REST directly works, the Python API is an easier way to communicate with the server.</p>
<p>You can also try running the test suite.
The suite is run using PyTest and you can optionally pass Pytest options to the command to filter and choose which tests to run.
Make sure you have the relevant test artifacts as described in the previous section.</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="c1"># this will start the server and test the REST API from Python.</span>
amdinfer <span class="nb">test</span>
</pre></div>
</div>
<p>Now that we can build and run the server, we will take a look at how to send requests to it using the Python API and link custom applications to the AMD Inference Server using the C++ API.</p>
</section>
</section>
</section>


           </div>
          </div>
          
                  <style>
                        .footer {
                        position: fixed;
                        left: 0;
                        bottom: 0;
                        width: 100%;
                        }
                  </style>
				  
				  <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="index.html" class="btn btn-neutral float-left" title="AMD Inference Server" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="hello_world_echo.html" class="btn btn-neutral float-right" title="Hello World - Python" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2022 Advanced Micro Devices, Inc..
      <span class="lastupdated">Last updated on November 18, 2022.
      </span></p>
  </div>



										<div class="aem-Grid aem-Grid--16">
											<div class="aem-GridColumn aem-GridColumn--xxxlarge--none aem-GridColumn--xsmall--16 aem-GridColumn--offset--xsmall--0 aem-GridColumn--xlarge--none aem-GridColumn--xxlarge--none aem-GridColumn--default--none aem-GridColumn--offset--large--1 aem-GridColumn--xlarge--12 aem-GridColumn--offset--default--0 aem-GridColumn--xxlarge--10 aem-GridColumn--offset--xlarge--2 aem-GridColumn--offset--xxlarge--3 aem-GridColumn--offset--xxxlarge--4 aem-GridColumn--xsmall--none aem-GridColumn--large--none aem-GridColumn aem-GridColumn--large--14 aem-GridColumn--xxxlarge--8 aem-GridColumn--default--16">
												<div class="container-fluid sub-footer">

													                    <div class="row">
                        <div class="col-xs-24">
                          <p><a target="_blank" href="https://www.amd.com/en/corporate/copyright">Terms and Conditions</a> | <a target="_blank" href="https://www.amd.com/en/corporate/privacy">Privacy</a> | <a target="_blank" href="https://www.amd.com/en/corporate/cookies">Cookie Policy</a> | <a target="_blank" href="https://www.amd.com/en/corporate/trademarks">Trademarks</a> | <a target="_blank" href="https://www.amd.com/system/files/documents/statement-human-trafficking-forced-labor.pdf">Statement on Forced Labor</a> | <a target="_blank" href="https://www.amd.com/en/corporate/competition">Fair and Open Competition</a> | <a target="_blank" href="https://www.amd.com/system/files/documents/amd-uk-tax-strategy.pdf">UK Tax Strategy</a> | <a target="_blank" href="https://docs.xilinx.com/v/u/9x6YvZKuWyhJId7y7RQQKA">Inclusive Terminology</a> | <a href="#cookiessettings" class="ot-sdk-show-settings">Cookies Settings</a></p>
                        </div>
                    </div>
												</div>
											</div>
										</div>
										
</br>


  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>
 <script type="text/javascript">
    $(document).ready(function() {
        $(".toggle > *").hide();
        $(".toggle .header").show();
        $(".toggle .header").click(function() {
            $(this).parent().children().not(".header").toggle(400);
            $(this).parent().children(".header").toggleClass("open");
        })
    });
</script>


</body>
</html>