<p>The REST endpoints are based on <a href="https://github.com/kserve/kserve/blob/master/docs/predict-api/v2/required_api.md">KServe’s v2 specification</a>. Additional endpoints are driven by community adoption.</p>
<h2>Health</h2>
<ul>
<li>
<p>GET <code>v2/health/live</code>: Check if the server is live</p>
</li>
<li>
<p>GET <code>v2/health/ready</code>: Check if the server is ready for inference requests</p>
</li>
<li>
<p>GET <code>v2/models/{model}/ready</code>: Check if a particular model is ready for inference requests</p>
</li>
</ul>
<h2>Metadata</h2>
<ul>
<li>
<p>GET <code>v2</code>: Get Xilinx Inference Server’s metadata</p>
</li>
<li>
<p>GET <code>v2/hardware</code>: Get a string describing the number and type of kernels that are available</p>
</li>
<li>
<p>GET <code>v2/models/{model}</code>: Get model metadata</p>
</li>
</ul>
<h2>Inference</h2>
<ul>
<li>
<p>POST <code>v2/repository/models/{model}/load</code>: Load a model. The HTML body in the response contains the endpoint to use for this model</p>
</li>
<li>
<p>POST <code>v2/repository/models/{model}/unload</code>: Unload a model</p>
</li>
<li>
<p>POST <code>v2/models/{model}/infer</code>: Make an inference request to a particular model</p>
</li>
</ul>
<h2>Observation</h2>
<ul>
<li>
<p>GET <code>metrics</code>: Get Prometheus metrics</p>
</li>
</ul>
