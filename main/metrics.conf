<p>Xilinx Inference Server exposes metrics using <a href="https://prometheus.io/">Prometheus</a> and they allow users to check Xilinx Inference Server’s state in real-time.</p>
<h2>Quickstart</h2>
<p>The easiest way to view the collected metrics is to run Prometheus as a binary in the container while an instrumented application runs. In the container:</p>
<ac:structured-macro ac:name="code">
<ac:parameter ac:name="language">none</ac:parameter>
<ac:parameter ac:name="linenumbers">false</ac:parameter>
<ac:plain-text-body><![CDATA[$ cd /tmp
$ wget https://github.com/prometheus/prometheus/releases/download/v2.30.1/prometheus-2.30.1.linux-amd64.tar.gz
$ tar -xzf prometheus-2.30.1.linux-amd64.tar.gz
$ cd /tmp/prometheus-2.30.1.linux-amd64
$ cp $PROTEUS_ROOT/src/proteus/observation/prometheus.yml .
$ ./prometheus]]></ac:plain-text-body>
</ac:structured-macro>
<p>By default, Prometheus will use a configuration file named <code>prometheus.yml</code> in the local directory. A sample <code>prometheus.yml</code> is provided in Xilinx Inference Server that can be used as-is or changed as needed. Documentation about the additional options for this file is available <a href="https://prometheus.io/docs/prometheus/latest/configuration/configuration/">online</a>.</p>
<p>Once the prometheus executable is running, start your instrumented application. The collected metrics can be viewed, queried and graphed at (by default) <code>localhost:9090</code> using Prometheus’s browser interface.</p>
