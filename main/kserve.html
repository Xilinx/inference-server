


<!DOCTYPE HTML>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
	<head>
		<meta charset="utf-8">
		<meta name="generator" content="Docutils 0.18.1: http://docutils.sourceforge.net/" />

		<meta http-equiv="content-type" content="text/html; charset=UTF-8"/>
		<link rel="stylesheet" href="https://static.cloud.coveo.com/searchui/v2.4382/css/CoveoFullSearch.css"/>
		<meta http-equiv="X-UA-Compatible" content="IE=edge"/>
		<meta name="viewport" content="width=device-width, initial-scale=1.0"/>
		<meta name="description"/>
		<meta name="keywords"/>
		<meta property="og:title" content=""/>
		<meta property="og:description"/>
		<!-- favicon -->
		<link rel="icon" type="image/vnd.microsoft.icon" href="_static/favicon.ico"/>
		<link rel="shortcut icon" type="image/vnd.microsoft.icon" href="_static/favicon.ico"/>
		<!-- Fonts -->
		<link href="https://fonts.googleapis.com/css?family=Roboto:300,400,500" rel="stylesheet" type="text/css"/>

	<!-- OneTrust Cookies Consent Notice start for xilinx.github.io -->
<script src="https://cdn.cookielaw.org/scripttemplates/otSDKStub.js" data-document-language="true" type="text/javascript" charset="UTF-8" data-domain-script="37701bd4-e5c0-4ee3-9329-e7475d0b13a7" ></script>
<script type="text/javascript">
function OptanonWrapper() { }
</script>
<!-- OneTrust Cookies Consent Notice end for xilinx.github.io -->
		<!-- Google Tag Manager -->
	<script type="text/plain" class="optanon-category-C0002">(function(w,d,s,l,i){w[l]=w[l]||[];w[l].push({'gtm.start':
	new Date().getTime(),event:'gtm.js'});var f=d.getElementsByTagName(s)[0],
	j=d.createElement(s),dl=l!='dataLayer'?'&l='+l:'';j.async=true;j.src=
	'//www.googletagmanager.com/gtm.js?id='+i+dl;f.parentNode.insertBefore(j,f);
	})(window,document,'script','dataLayer','GTM-5RHQV7');</script>
	<!-- End Google Tag Manager -->
	
        <!-- Google Tag Manager -->
        <noscript><iframe src="//www.googletagmanager.com/ns.html?id=GTM-5RHQV7" height="0" width="0" style="display:none;visibility:hidden" class="optanon-category-C0002"></iframe></noscript>
        <!-- End Google Tag Manager -->	

  
  
  
  

  
      <script type="text/javascript" src="_static/js/jquery.min.js"></script>
	  <script type="text/javascript" src="_static/js/gtm.js"></script>
  <script type="text/javascript" src="_static/js/modernizr.min.js"></script>
    <script type="text/javascript" src="_static/js/d3dd8c60ed.js"></script>
    <script type="text/javascript" src="_static/js/common-ui-all.min.js"></script>
    <script type="text/javascript" src="_static/js/jquery-ui.min.js"></script>
    <script type="text/javascript" src="_static/js/CoveoJsSearch.Lazy.min.js"></script>
    <script type="text/javascript" src="_static/js/linkid.js"></script>
    <script type="text/javascript" src="_static/js/Searchbox.min.js"></script>
    <script type="text/javascript" src="_static/js/header-footer.min.js"></script>
  
    
      <script type="text/javascript" id="documentation_options" data-url_root="./" src="_static/documentation_options.js"></script>
        <script data-url_root="./" id="documentation_options" src="_static/documentation_options.js"></script>
        <script src="_static/jquery.js"></script>
        <script src="_static/underscore.js"></script>
        <script src="_static/_sphinx_javascript_frameworks_compat.js"></script>
        <script src="_static/doctools.js"></script>
        <script src="_static/sphinx_highlight.js"></script>
        <script src="_static/clipboard.min.js"></script>
        <script src="_static/copybutton.js"></script>
    
    <script type="text/javascript" src="_static/js/theme.js"></script>

    

  
  <link rel="stylesheet" href="_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="_static/css/common-ui-all.min.css" type="text/css" />
  <link rel="stylesheet" href="_static/css/header-footer.min.css" type="text/css" />
  <link rel="stylesheet" href="_static/css/pro.min.css" media="all" />
  <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="_static/copybutton.css" type="text/css" />
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="Factors" href="performance_factors.html" />
    <link rel="prev" title="Docker" href="docker.html" /> 
	</head>
	<body>
		<div class="xilinx-bs3"/>
		<div class="root responsivegrid">
			<div class="aem-Grid aem-Grid--16 aem-Grid--default--16 aem-Grid--large--16 aem-Grid--xlarge--16 aem-Grid--xxlarge--16 aem-Grid--xxxlarge--16 ">
 <div class="xilinxExperienceFragments experiencefragment aem-GridColumn aem-GridColumn--default--12">

    
    

    



<div class="xf-content-height">
    

<div class="aem-Grid aem-Grid--16 aem-Grid--default--16 ">
    
    <div class="header parbase aem-GridColumn aem-GridColumn--default--12"><noindex>
	<header data-component="header" class="site-header">
		<nav class="navbar navbar-default">
			<div class="container-fluid main-nav">
				<div class="row">
					<div class="navbar-column col-xs-4 col-sm-5">
						<ul class="nav navbar-nav hidden-xs">
							<li>
									<button onclick="window.location.href=&#39;https://www.xilinx.com/applications.html&#39;;">Solutions</button>
								</li>
							<li>
									<button onclick="window.location.href=&#39;https://www.xilinx.com/products/silicon-devices.html&#39;;">Products</button>
								</li>
							<li>
									<button onclick="window.location.href=&#39;https://www.xilinx.com/about/company-overview.html&#39;;">Company</button>
								</li>
							</ul>
							
						<ul class="nav navbar-nav hidden-sm hidden-md hidden-lg">
							<li>
									<button data-target="#header-container-0" data-function="toggle">Solutions</button>
								</li>
							<li>
									<button data-target="#header-container-1" data-function="toggle">Products</button>
								</li>
							<li>
									<button data-target="#header-container-2" data-function="toggle">Company</button>
								</li>
							</ul>
							
						<div id="header-container-0" class="menu-container">
								<div class="navbar-nav-container">
									<ul class="nav navbar-nav">
										<li>
												<button onclick="window.location.href=&#39;https://www.xilinx.com/applications.html&#39;;">Solutions</button>
												</li>
										<li>
												<button onclick="window.location.href=&#39;https://www.xilinx.com/products/silicon-devices.html&#39;;">Products</button>
												</li>
										<li>
												<button onclick="window.location.href=&#39;https://www.xilinx.com/about/company-overview.html&#39;;">Company</button>
												</li>
										</ul>
									<button data-function="close-menu">
										<span class="fal fa-times" aria-hidden="true"></span>
									</button>
								</div>
							</div>
							<div id="header-container-1" class="menu-container">
								<div class="navbar-nav-container">
									<ul class="nav navbar-nav">
										<li>
												<button onclick="window.location.href=&#39;https://www.xilinx.com/applications.html&#39;;">Solutions</button>
												</li>
										<li>
												<button onclick="window.location.href=&#39;https://www.xilinx.com/products/silicon-devices.html&#39;;">Products</button>
												</li>
										<li>
												<button onclick="window.location.href=&#39;https://www.xilinx.com/about/company-overview.html&#39;;">Company</button>
												</li>
										</ul>
									<button data-function="close-menu">
										<span class="fal fa-times" aria-hidden="true"></span>
									</button>
								</div>
							</div>
							<div id="header-container-2" class="menu-container">
								<div class="navbar-nav-container">
									<ul class="nav navbar-nav">
										<li>
												<button onclick="window.location.href=&#39;https://www.xilinx.com/applications.html&#39;;">Solutions</button>
												</li>
										<li>
												<button onclick="window.location.href=&#39;https://www.xilinx.com/products/silicon-devices.html&#39;;">Products</button>
												</li>
										<li>
												<button onclick="window.location.href=&#39;https://www.xilinx.com/about/company-overview.html&#39;;">Company</button>
												</li>
										</ul>
									<button data-function="close-menu">
										<span class="fal fa-times" aria-hidden="true"></span>
									</button>
								</div>
							</div>
							</div>
					<div class="logo-column col-xs-4 col-sm-2">
						<div class="logo">
							<a target="_blank" href="https://www.xilinx.com/">
								<img src="https://github.com/Xilinx/Image-Collateral/blob/main/xilinx-header-logo.svg?raw=true" title="Xilinx Inc"/>
							</a>
						</div>
					</div>

				</div>
			</div>
			</nav></header></noindex></div>
		
	
</div>

    
</div>
</div>

<div class="calloutBanner parbase aem-GridColumn--default--none aem-GridColumn aem-GridColumn--offset--default--0 aem-GridColumn--default--16"><div class="callout-banner">
    Xilinx is now a part of <a target="_blank" href="https://www.amd.com/en/corporate/xilinx-acquisition">AMD</a> |  <a target="_blank" href="https://www.amd.com/en/corporate/privacy">Learn More</a>
</div>
</div>
				<div class="parsys aem-GridColumn--xxxlarge--none aem-GridColumn--xlarge--none aem-GridColumn--xxlarge--none aem-GridColumn--default--none aem-GridColumn--offset--large--1 aem-GridColumn--xlarge--12 aem-GridColumn--offset--default--0 aem-GridColumn--xxlarge--10 aem-GridColumn--offset--xlarge--2 aem-GridColumn--offset--xxlarge--3 aem-GridColumn--offset--xxxlarge--4 aem-GridColumn--large--none aem-GridColumn aem-GridColumn--large--14 aem-GridColumn--xxxlarge--8 aem-GridColumn--default--16">
						<div class="container-fluid">
							<div class="row">
							<div class="col-xs-12">
   
  <div class="wy-grid-for-nav">
    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
          

          
            <a href="index.html" class="icon icon-home" alt="Documentation Home"> AMD Inference Server
          

          
          </a>

          
            
            
              <div class="version">
                main
              </div>
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

      
        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
            
            
            
              
            
            
              <ul>
<li class="toctree-l1"><a class="reference internal" href="index.html">AMD Inference Server</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Getting Started</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="quickstart.html">Quickstart</a></li>
<li class="toctree-l1"><a class="reference internal" href="hello_world_echo.html">Hello World - Python</a></li>
<li class="toctree-l1"><a class="reference internal" href="example_resnet50_cpp.html">Running ResNet50 - C++</a></li>
<li class="toctree-l1"><a class="reference internal" href="example_resnet50_python.html">Running ResNet50 - Python</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Using AMD Inference Server</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="aks.html">AKS</a></li>
<li class="toctree-l1"><a class="reference internal" href="logging.html">Logs</a></li>
<li class="toctree-l1"><a class="reference internal" href="benchmarking.html">Benchmarking</a></li>
<li class="toctree-l1"><a class="reference internal" href="metrics.html">Metrics</a></li>
<li class="toctree-l1"><a class="reference internal" href="tracing.html">Tracing</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Platforms</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="vitis_ai.html">Vitis AI</a></li>
<li class="toctree-l1"><a class="reference internal" href="zendnn.html">ZenDNN</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Deployment</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="docker.html">Docker</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">KServe</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#set-up-kubernetes-and-kserve">Set up Kubernetes and KServe</a></li>
<li class="toctree-l2"><a class="reference internal" href="#get-or-build-the-amd-inference-server-image">Get or build the AMD Inference Server Image</a></li>
<li class="toctree-l2"><a class="reference internal" href="#start-an-inference-service">Start an inference service</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#serving-runtime">Serving Runtime</a></li>
<li class="toctree-l3"><a class="reference internal" href="#custom-container">Custom container</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#making-requests">Making Requests</a></li>
<li class="toctree-l2"><a class="reference internal" href="#debugging">Debugging</a></li>
</ul>
</li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Getting Performance</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="performance_factors.html">Factors</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">User API libraries</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="rest.html">REST Endpoints</a></li>
<li class="toctree-l1"><a class="reference internal" href="cpp_api.html">C++ API</a></li>
<li class="toctree-l1"><a class="reference internal" href="python.html">Python</a></li>
<li class="toctree-l1"><a class="reference internal" href="cli.html">Command-Line Interface</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Developers</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="architecture.html">Architecture</a></li>
<li class="toctree-l1"><a class="reference internal" href="contributing.html">Contributing</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">About</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="roadmap.html">Roadmap</a></li>
<li class="toctree-l1"><a class="reference internal" href="changelog.html">Changelog</a></li>
<li class="toctree-l1"><a class="reference internal" href="dependencies.html">Dependencies</a></li>
</ul>

            
			
			<p class="caption"><span class="caption-text">This Page</span></p>
				<ul class="current">
				  <li class="toctree-l1"><a href="_sources/kserve.rst.txt"
						rel="nofollow">Show Source</a></li>
				</ul>
          
        </div>
        
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="index.html">AMD Inference Server</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="index.html" class="icon icon-home"></a> &raquo;</li>
        
      <li>KServe</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
            
            <a href="_sources/kserve.rst.txt" rel="nofollow"> View page source</a>
          
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <section id="kserve">
<span id="id1"></span><h1>KServe<a class="headerlink" href="#kserve" title="Permalink to this heading">¶</a></h1>
<p>You can use the AMD Inference Server with <a class="reference external" href="https://github.com/kserve/kserve">KServe</a> to deploy the server on a Kubernetes cluster.</p>
<section id="set-up-kubernetes-and-kserve">
<h2>Set up Kubernetes and KServe<a class="headerlink" href="#set-up-kubernetes-and-kserve" title="Permalink to this heading">¶</a></h2>
<p>To use KServe, you will need a Kubernetes cluster.
There are many ways to set up and configure a Kubernetes cluster depending on your use cases.
Instructions for installing and configuring Kubernetes are out of this scope.</p>
<p>Install KServe using the <a class="reference external" href="https://kserve.github.io/website/admin/serverless/">instructions</a> provided by KServe.
We have tested with KServe 0.8 using the standard serverless installation but other versions/configurations may work as well.
Once KServe is installed, verify basic functionality of the cluster using KServe’s <a class="reference external" href="https://kserve.github.io/website/get_started/first_isvc/">basic tutorial</a>.
If this succeeds, KServe should be installed correctly.
KServe installation help and debugging are also out of scope for these instructions.
If you run into problems, reach out to the KServe project.</p>
<p>If you want to use FPGAs for your inferences, install the <a class="reference external" href="https://github.com/Xilinx/FPGA_as_a_Service/tree/master/k8s-fpga-device-plugin">Xilinx FPGA Kubernetes plugin</a>.
This plugin adds FPGAs as a resource for Kubernetes so you can request them when launching services on your cluster.</p>
<p>You may also want to install monitoring and tracing tools such as Prometheus, Jaeger, and Grafana to your Kubernetes cluster.
Refer to the documentation for these respective projects on installation details.
The <a class="reference external" href="https://github.com/prometheus-operator/kube-prometheus/">kube-prometheus</a> project is a good starting point to install some of these tools.</p>
</section>
<section id="get-or-build-the-amd-inference-server-image">
<h2>Get or build the AMD Inference Server Image<a class="headerlink" href="#get-or-build-the-amd-inference-server-image" title="Permalink to this heading">¶</a></h2>
<p>To use with KServe, you will need to pull or <span class="xref std std-ref">build the production container &lt;docker:Build the production Docker image</span>.
Once you have it somewhere, make sure you can use <code class="docutils literal notranslate"><span class="pre">docker</span> <span class="pre">pull</span> <span class="pre">&lt;image&gt;</span></code> on all the nodes in the Kubernetes cluster to get the image.</p>
</section>
<section id="start-an-inference-service">
<h2>Start an inference service<a class="headerlink" href="#start-an-inference-service" title="Permalink to this heading">¶</a></h2>
<p>Services in Kubernetes can be started with YAML configuration files.
To add a service to your cluster, create the configuration file and use <code class="docutils literal notranslate"><span class="pre">kubectl</span> <span class="pre">apply</span> <span class="pre">-f</span> <span class="pre">&lt;path</span> <span class="pre">to</span> <span class="pre">yaml</span> <span class="pre">file&gt;</span></code>.
KServe provides a number of Custom Resource Definitions (CRDs) that you can use to serve inferences with the AMD Inference Server.
The current recommended approach from KServe is to use the <code class="docutils literal notranslate"><span class="pre">ServingRuntime</span></code> method.</p>
<p>As you start an inference service, you will need models to serve.
The model format for the AMD Inference Server is the following:</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>/
├─ model_a/
│  ├─ 1/
│  │  ├─ saved_model.x
│  ├─ config.pbtxt
</pre></div>
</div>
<p>The model name, <code class="docutils literal notranslate"><span class="pre">model_a</span></code> in this template, must be unique among the models loaded on a particular server.
This name is used to name the endpoint used to make inference requests to.
Under this directory, there must be a directory named <code class="docutils literal notranslate"><span class="pre">1/</span></code> containing the model file itself and a text file named <code class="docutils literal notranslate"><span class="pre">config.pbtxt</span></code>.
The model file must be named <code class="docutils literal notranslate"><span class="pre">saved_model</span></code> and the file extension depends on the type of the model.
The <code class="docutils literal notranslate"><span class="pre">config.pbtxt</span></code> file contains metadata for the model.
Consider this example of an MNIST TensorFlow model:</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>name: &quot;mnist&quot;
platform: &quot;tensorflow_graphdef&quot;
inputs [
  {
    name: &quot;images_in&quot;
    datatype: &quot;FP32&quot;
    shape: [28,28,1]
  }
]
outputs [
  {
    name: &quot;flatten/Reshape&quot;
    datatype: &quot;FP32&quot;
    shape: [10]
  }
]
</pre></div>
</div>
<p>The name must match the name of the model directory, i.e. <code class="docutils literal notranslate"><span class="pre">model_a</span></code>.
The platform identifies the type of the model and determines the file extension of the model file.
The supported platforms are:</p>
<table class="docutils align-default" style="width: 22em">
<colgroup>
<col style="width: 90%" />
<col style="width: 10%" />
</colgroup>
<thead>
<tr class="row-odd"><th class="head"><p>Platform</p></th>
<th class="head"><p>Model file extension</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">tensorflow_graphdef</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">.pb</span></code></p></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">pytorch_torchscript</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">.pt</span></code></p></td>
</tr>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">vitis_xmodel</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">.xmodel</span></code></p></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">onnx_onnxv1</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">.onnx</span></code></p></td>
</tr>
</tbody>
</table>
<p>The inputs and outputs define the list of input and output tensors for the model.
The names of the tensors may be significant if the platform needs them to perform inference.</p>
<p>You can put the model up on any of the cloud storage platforms that KServe supports like GCS, S3 and HTTP.
If you use HTTP, the model should be zipped.
Other archive formats such as <code class="docutils literal notranslate"><span class="pre">.tar.gz</span></code> may not work as expected.
Wherever you store it, the URI will be needed to start inference services.</p>
<section id="serving-runtime">
<h3>Serving Runtime<a class="headerlink" href="#serving-runtime" title="Permalink to this heading">¶</a></h3>
<p>KServe defines two CRDs called <code class="docutils literal notranslate"><span class="pre">ServingRuntime</span></code> and <code class="docutils literal notranslate"><span class="pre">ClusterServingRuntime</span></code>, where the only difference is that the former is namespace-scoped and the latter is cluster-scoped.
You can see more information about these CRDs in <a class="reference external" href="https://kserve.github.io/website/0.9/modelserving/servingruntimes/">KServe’s documentation</a>.
The AMD Inference Server is not included by default in the standard KServe installation but you can add the runtime to your cluster.
A sample <code class="docutils literal notranslate"><span class="pre">ClusterServingRuntime</span></code> definition is provided below.</p>
<div class="highlight-yaml notranslate"><div class="highlight"><pre><span></span><span class="nn">---</span><span class="w"></span>
<span class="nt">apiVersion</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">serving.kserve.io/v1alpha1</span><span class="w"></span>
<span class="nt">kind</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">ClusterServingRuntime</span><span class="w"></span>
<span class="nt">metadata</span><span class="p">:</span><span class="w"></span>
<span class="w">  </span><span class="c1"># this is the name of the runtime to add</span><span class="w"></span>
<span class="w">  </span><span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">kserve-amdserver</span><span class="w"></span>
<span class="nt">spec</span><span class="p">:</span><span class="w"></span>
<span class="w">  </span><span class="nt">supportedModelFormats</span><span class="p">:</span><span class="w"></span>
<span class="w">    </span><span class="c1"># depending on the image you&#39;re using, and which platforms are added,</span><span class="w"></span>
<span class="w">    </span><span class="c1"># the supported formats could be different. For example, this assumes</span><span class="w"></span>
<span class="w">    </span><span class="c1"># that a ZenDNN image was created with both TF+ZenDNN and PT+ZenDNN</span><span class="w"></span>
<span class="w">    </span><span class="c1"># support</span><span class="w"></span>
<span class="w">    </span><span class="p p-Indicator">-</span><span class="w"> </span><span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">tensorflow</span><span class="w"></span>
<span class="w">      </span><span class="nt">version</span><span class="p">:</span><span class="w"> </span><span class="s">&quot;2&quot;</span><span class="w"></span>
<span class="w">    </span><span class="p p-Indicator">-</span><span class="w"> </span><span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">pytorch</span><span class="w"></span>
<span class="w">      </span><span class="nt">version</span><span class="p">:</span><span class="w"> </span><span class="s">&quot;1&quot;</span><span class="w"></span>
<span class="w">  </span><span class="nt">protocolVersions</span><span class="p">:</span><span class="w"></span>
<span class="w">    </span><span class="c1"># depending on the image you&#39;re using, it may not support both HTTP/REST</span><span class="w"></span>
<span class="w">    </span><span class="c1"># and gRPC, respectively. By default, both protocols are supported.</span><span class="w"></span>
<span class="w">    </span><span class="p p-Indicator">-</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">v2</span><span class="w"></span>
<span class="w">    </span><span class="p p-Indicator">-</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">grpc-v2</span><span class="w"></span>
<span class="w">  </span><span class="nt">containers</span><span class="p">:</span><span class="w"></span>
<span class="w">    </span><span class="p p-Indicator">-</span><span class="w"> </span><span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">kserve-container</span><span class="w"></span>
<span class="w">      </span><span class="c1"># provide the image name. The usual rules around images apply (see</span><span class="w"></span>
<span class="w">      </span><span class="c1"># above in the section &quot;Build the AMD Inference Server Image&quot;)</span><span class="w"></span>
<span class="w">      </span><span class="nt">image</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">&lt;your image&gt;</span><span class="w"></span>
<span class="w">      </span><span class="c1"># when the image starts, it will automatically launch the server</span><span class="w"></span>
<span class="w">      </span><span class="c1"># executable with the following arguments. While the ports used by</span><span class="w"></span>
<span class="w">      </span><span class="c1"># the server are configurable, there are some assumptions in KServe</span><span class="w"></span>
<span class="w">      </span><span class="c1"># with the default port values so it is recommended to not change them</span><span class="w"></span>
<span class="w">      </span><span class="nt">args</span><span class="p">:</span><span class="w"></span>
<span class="w">        </span><span class="p p-Indicator">-</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">proteus-server</span><span class="w"></span>
<span class="w">        </span><span class="p p-Indicator">-</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">--model-repository=/mnt/models</span><span class="w"></span>
<span class="w">        </span><span class="p p-Indicator">-</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">--enable-repository-watcher</span><span class="w"></span>
<span class="w">        </span><span class="p p-Indicator">-</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">--grpc-port=9000</span><span class="w"></span>
<span class="w">        </span><span class="p p-Indicator">-</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">--http-port=8080</span><span class="w"></span>
<span class="w">      </span><span class="c1"># the resources allowed to the service. If the image needs access to</span><span class="w"></span>
<span class="w">      </span><span class="c1"># hardware like FPGAs or GPUs, then those resources need to be added</span><span class="w"></span>
<span class="w">      </span><span class="c1"># here so Kubernetes can schedule pods on the appropriate nodes.</span><span class="w"></span>
<span class="w">      </span><span class="nt">resources</span><span class="p">:</span><span class="w"></span>
<span class="w">        </span><span class="nt">requests</span><span class="p">:</span><span class="w"></span>
<span class="w">          </span><span class="nt">cpu</span><span class="p">:</span><span class="w"> </span><span class="s">&quot;1&quot;</span><span class="w"></span>
<span class="w">          </span><span class="nt">memory</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">2Gi</span><span class="w"></span>
<span class="w">        </span><span class="nt">limits</span><span class="p">:</span><span class="w"></span>
<span class="w">          </span><span class="nt">cpu</span><span class="p">:</span><span class="w"> </span><span class="s">&quot;1&quot;</span><span class="w"></span>
<span class="w">          </span><span class="nt">memory</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">2Gi</span><span class="w"></span>
</pre></div>
</div>
<p>Adding a <code class="docutils literal notranslate"><span class="pre">ClusterServingRuntime</span></code> or a <code class="docutils literal notranslate"><span class="pre">ServingRuntime</span></code> is a one-time action per cluster.
Once it’s added, you can launch inference services using the runtime like:</p>
<div class="highlight-yaml notranslate"><div class="highlight"><pre><span></span><span class="nn">---</span><span class="w"></span>
<span class="nt">apiVersion</span><span class="p">:</span><span class="w"> </span><span class="s">&quot;serving.kserve.io/v1beta1&quot;</span><span class="w"></span>
<span class="nt">kind</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">InferenceService</span><span class="w"></span>
<span class="nt">metadata</span><span class="p">:</span><span class="w"></span>
<span class="w">  </span><span class="nt">annotations</span><span class="p">:</span><span class="w"></span>
<span class="w">    </span><span class="c1"># The autoscaling target defines how the service should be auto-scale in</span><span class="w"></span>
<span class="w">    </span><span class="c1"># response to incoming requests. The value of 5 indicates that</span><span class="w"></span>
<span class="w">    </span><span class="c1"># additional containers should be deployed when the number of concurrent</span><span class="w"></span>
<span class="w">    </span><span class="c1"># requests exceeds 5.</span><span class="w"></span>
<span class="w">    </span><span class="nt">autoscaling.knative.dev/target</span><span class="p">:</span><span class="w"> </span><span class="s">&quot;5&quot;</span><span class="w"></span>
<span class="w">  </span><span class="nt">labels</span><span class="p">:</span><span class="w"></span>
<span class="w">    </span><span class="nt">controller-tools.k8s.io</span><span class="p">:</span><span class="w"> </span><span class="s">&quot;1.0&quot;</span><span class="w"></span>
<span class="w">    </span><span class="nt">app</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">example-amdserver-runtime-isvc</span><span class="w"></span>
<span class="w">  </span><span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">example-amdserver-runtime-isvc</span><span class="w"></span>
<span class="nt">spec</span><span class="p">:</span><span class="w"></span>
<span class="w">  </span><span class="nt">predictor</span><span class="p">:</span><span class="w"></span>
<span class="w">    </span><span class="nt">model</span><span class="p">:</span><span class="w"></span>
<span class="w">      </span><span class="nt">modelFormat</span><span class="p">:</span><span class="w"></span>
<span class="w">        </span><span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">tensorflow</span><span class="w"></span>
<span class="w">      </span><span class="nt">storageUri</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">url/to/model</span><span class="w"></span>
<span class="w">      </span><span class="c1"># while it&#39;s optional for KServe, the runtime should be explicitly</span><span class="w"></span>
<span class="w">      </span><span class="c1"># specified to make sure the runtime you&#39;ve added for the AMD Inference</span><span class="w"></span>
<span class="w">      </span><span class="c1"># Server is used</span><span class="w"></span>
<span class="w">      </span><span class="nt">runtime</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">kserve-amdserver</span><span class="w"></span>
</pre></div>
</div>
</section>
<section id="custom-container">
<h3>Custom container<a class="headerlink" href="#custom-container" title="Permalink to this heading">¶</a></h3>
<p>This approach uses an older method of starting inference services using the <code class="docutils literal notranslate"><span class="pre">InferenceService</span></code> and <code class="docutils literal notranslate"><span class="pre">TrainedModel</span></code> CRDs, where you start a custom container directly and add models to it.
Initially, no models are loaded on the server as it uses the multi-model serving mechanism of KServe that was a precursor to ModelMesh to support inference servers running multiple models.
Once an <code class="docutils literal notranslate"><span class="pre">InferenceService</span></code> is up, you can load models to it by applying one or more <code class="docutils literal notranslate"><span class="pre">TrainedModel</span></code> CRDs.
Each such load adds a model to the server and makes it available for inference requests.
A sample YAML file is provided below.</p>
<div class="highlight-yaml notranslate"><div class="highlight"><pre><span></span><span class="nn">---</span><span class="w"></span>
<span class="nt">apiVersion</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">serving.kserve.io/v1beta1</span><span class="w"></span>
<span class="nt">kind</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">InferenceService</span><span class="w"></span>
<span class="nt">metadata</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">null</span><span class="w"></span>
<span class="nt">annotations</span><span class="p">:</span><span class="w"></span>
<span class="w">  </span><span class="c1"># The autoscaling target defines how the service should be auto-scaled in</span><span class="w"></span>
<span class="w">  </span><span class="c1"># response to incoming requests. The value of 5 indicates that additional</span><span class="w"></span>
<span class="w">  </span><span class="c1"># containers should be deployed when the number of concurrent requests</span><span class="w"></span>
<span class="w">  </span><span class="c1"># exceeds 5.</span><span class="w"></span>
<span class="w">  </span><span class="nt">autoscaling.knative.dev/target</span><span class="p">:</span><span class="w"> </span><span class="s">&#39;5&#39;</span><span class="w"></span>
<span class="nt">labels</span><span class="p">:</span><span class="w"></span>
<span class="w">  </span><span class="nt">controller-tools.k8s.io</span><span class="p">:</span><span class="w"> </span><span class="s">&#39;1.0&#39;</span><span class="w"></span>
<span class="w">  </span><span class="nt">app</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">example-amdserver-multi-isvc</span><span class="w"></span>
<span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">example-amdserver-multi-isvc</span><span class="w"></span>
<span class="nt">spec</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">null</span><span class="w"></span>
<span class="nt">predictor</span><span class="p">:</span><span class="w"></span>
<span class="w">  </span><span class="nt">containers</span><span class="p">:</span><span class="w"></span>
<span class="w">    </span><span class="p p-Indicator">-</span><span class="w"> </span><span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">custom</span><span class="w"></span>
<span class="w">      </span><span class="nt">image</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">&lt;your image&gt;</span><span class="w"></span>
<span class="w">      </span><span class="nt">env</span><span class="p">:</span><span class="w"></span>
<span class="w">        </span><span class="p p-Indicator">-</span><span class="w"> </span><span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">MULTI_MODEL_SERVER</span><span class="w"></span>
<span class="w">          </span><span class="nt">value</span><span class="p">:</span><span class="w"> </span><span class="s">&#39;true&#39;</span><span class="w"></span>
<span class="w">      </span><span class="nt">args</span><span class="p">:</span><span class="w"></span>
<span class="w">        </span><span class="p p-Indicator">-</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">proteus-server</span><span class="w"></span>
<span class="w">        </span><span class="p p-Indicator">-</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">--model-repository=/mnt/models</span><span class="w"></span>
<span class="w">        </span><span class="p p-Indicator">-</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">--http-port=8080</span><span class="w"></span>
<span class="w">        </span><span class="p p-Indicator">-</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">--grpc-port=9000</span><span class="w"></span>
<span class="w">      </span><span class="nt">ports</span><span class="p">:</span><span class="w"></span>
<span class="w">        </span><span class="p p-Indicator">-</span><span class="w"> </span><span class="nt">containerPort</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">8080</span><span class="w"></span>
<span class="w">          </span><span class="nt">protocol</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">TCP</span><span class="w"></span>
<span class="w">        </span><span class="p p-Indicator">-</span><span class="w"> </span><span class="nt">containerPort</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">9000</span><span class="w"></span>
<span class="w">          </span><span class="nt">protocol</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">TCP</span><span class="w"></span>
<span class="nn">---</span><span class="w"></span>
<span class="nt">apiVersion</span><span class="p">:</span><span class="w"> </span><span class="s">&quot;serving.kserve.io/v1alpha1&quot;</span><span class="w"></span>
<span class="nt">kind</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">TrainedModel</span><span class="w"></span>
<span class="nt">metadata</span><span class="p">:</span><span class="w"></span>
<span class="w">  </span><span class="c1"># this name is significant and must match the top-level directory in the</span><span class="w"></span>
<span class="w">  </span><span class="c1"># downloaded model at the storageUri. This string becomes the endpoint u</span><span class="w"></span>
<span class="w">  </span><span class="c1"># used to make inferences</span><span class="w"></span>
<span class="w">  </span><span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">&lt;name of the model&gt;</span><span class="w"></span>
<span class="nt">spec</span><span class="p">:</span><span class="w"></span>
<span class="w">  </span><span class="c1"># the name used here must match an existing InferenceService to load</span><span class="w"></span>
<span class="w">  </span><span class="c1"># this TrainedModel to</span><span class="w"></span>
<span class="w">  </span><span class="nt">inferenceService</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">example-amdserver-multi-isvc</span><span class="w"></span>
<span class="w">  </span><span class="nt">model</span><span class="p">:</span><span class="w"></span>
<span class="w">    </span><span class="nt">framework</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">tensorflow</span><span class="w"></span>
<span class="w">    </span><span class="nt">storageUri</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">url/to/model</span><span class="w"></span>
<span class="w">    </span><span class="nt">memory</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">1Gi</span><span class="w"></span>
</pre></div>
</div>
</section>
</section>
<section id="making-requests">
<h2>Making Requests<a class="headerlink" href="#making-requests" title="Permalink to this heading">¶</a></h2>
<p>The method by which you communicate with your service depends on your Kubernetes cluster configuration.
For example, one way to make requests is to <a class="reference external" href="https://kserve.github.io/website/master/get_started/first_isvc/#4-determine-the-ingress-ip-and-ports">get the address of the INGRESS_HOST and INGRESS_PORT</a>, and then make requests to this URL by setting the <code class="docutils literal notranslate"><span class="pre">Host</span></code> header on all requests to your targeted service.
This use case may be needed if your cluster doesn’t have a load-balancer and/or DNS enabled.</p>
<p>Once you can communicate with your service, you can make requests to the Inference Server using REST with cURL or the <a class="reference external" href="https://kserve.github.io/website/0.8/sdk_docs/sdk_doc/">KServe Python API</a>.
The request will be routed to the server and the response will be returned.
You can see some examples of using the KServe Python API to make requests in the <a class="reference external" href="https://github.com/Xilinx/inference-server/tree/main/tests/kserve">tests</a>.</p>
</section>
<section id="debugging">
<h2>Debugging<a class="headerlink" href="#debugging" title="Permalink to this heading">¶</a></h2>
<p>Debugging the inference server with KServe adds some additional complexity.
You may have issues with your KServe installation itself (in which case you need to debug KServe alone until you can <a class="reference external" href="https://kserve.github.io/website/get_started/first_isvc/">run a basic InferenceService</a>).
Once the default KServe example works, then you can begin debugging any inference server specific issues.</p>
<p>Use <code class="docutils literal notranslate"><span class="pre">kubectl</span> <span class="pre">logs</span> <span class="pre">&lt;pod_name&gt;</span> <span class="pre">&lt;container&gt;</span></code> to see the logs associated with the failing pod.
You’ll need to use <code class="docutils literal notranslate"><span class="pre">kubectl</span> <span class="pre">get</span> <span class="pre">pods</span></code> to get the name of the pods corresponding to the InferenceService you’re attempting to debug.
The <code class="docutils literal notranslate"><span class="pre">logs</span></code> command will list the containers in this pod (if more than one exist) and prompt you to specify the container whose logs you’re interested in.
These logs may have helpful error messages.</p>
<p>You can also directly connect to the inference server container that’s running in KServe with Docker.
The easiest way to do this is with the <code class="docutils literal notranslate"><span class="pre">proteus</span></code> script in the inference server repository.
You’ll need to first connect to the node where the container is running.
On that host:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="c1"># this lists the running Inference Server containers</span>
proteus list

<span class="c1"># get the container ID of the container you want to connect to</span>

<span class="c1"># provide the ID as an argument to the attach command to open a bash shell</span>
<span class="c1"># in the container</span>
proteus attach -n &lt;container ID&gt;
</pre></div>
</div>
<p>Once in the container, you can find the running <code class="docutils literal notranslate"><span class="pre">proteus-server</span></code> executable and then follow the regular debugging guide to debug the inference server.</p>
</section>
</section>


           </div>
           
          </div>
          <footer>
<!-- Atalwar: Moved the footer code to layout.html to resolve conflict with the Xilinx template -->
</footer>

        </div>
      </div>


	  <!-- Sphinx Page Footer block -->
  
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
        <a href="performance_factors.html" class="btn btn-neutral float-right" title="Factors" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right"></span></a>
      
      
        <a href="docker.html" class="btn btn-neutral float-left" title="Docker" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left"></span> Previous</a>
      
    </div>
  

  <hr/>

  <div role="contentinfo" class="copyright">
    <p class="footerinfo">
      <span class="lastupdated">
        Last updated on November 09, 2022.
      </span>

    </p>
	<br>
  </div>
      </div>
    </section>


  

  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

   <script type="text/javascript">
    jQuery(function() { Search.loadIndex("searchindex.js"); });
  </script>

  <script type="text/javascript" id="searchindexloader"></script>


  
  
    
  



  <!--  Xilinx template footer block -->
							</div>
						</div>
					</div>
				</div>
				<div class="xilinxExperienceFragments experiencefragment aem-GridColumn--default--none aem-GridColumn aem-GridColumn--offset--default--0 aem-GridColumn--default--16">
					<div class="xf-content-height">
						<div class="aem-Grid aem-Grid--16 aem-Grid--default--16 ">
							<div class="footer parbase aem-GridColumn--default--none aem-GridColumn aem-GridColumn--offset--default--0 aem-GridColumn--default--16">
								<noindex>
                  <!-- make footer fixed - NileshP -->
                  <style>
                        .footer {
                        position: fixed;
                        left: 0;
                        bottom: 0;
                        width: 100%;
                        }
                  </style>
                  <!-- make footer fixed NileshP-->
									<footer>
										<div class="aem-Grid aem-Grid--16">
											<div class="aem-GridColumn aem-GridColumn--xxxlarge--none aem-GridColumn--xsmall--16 aem-GridColumn--offset--xsmall--0 aem-GridColumn--xlarge--none aem-GridColumn--xxlarge--none aem-GridColumn--default--none aem-GridColumn--offset--large--1 aem-GridColumn--xlarge--12 aem-GridColumn--offset--default--0 aem-GridColumn--xxlarge--10 aem-GridColumn--offset--xlarge--2 aem-GridColumn--offset--xxlarge--3 aem-GridColumn--offset--xxxlarge--4 aem-GridColumn--xsmall--none aem-GridColumn--large--none aem-GridColumn aem-GridColumn--large--14 aem-GridColumn--xxxlarge--8 aem-GridColumn--default--16">
												<div class="container-fluid sub-footer">
													<div class="row">
														<div class="footerSocial parbase">
														
															<div class="col-md-push-6 col-lg-push-6 col-md-6 col-lg-6">
																<div class="lang-select dropup hidden-md hidden-lg">
		<button data-toggle="dropdown">
			<span class="fas fa-globe" aria-hidden="true"></span>
			<span>
				
					English
				</span>
		<span class="far fa-angle-down" aria-hidden="true"></span>
	</button>
	<ul class="dropdown-menu">
		<li>
				<a target="_blank" href="https://japan.xilinx.com/" target="_self">
					日本語
				</a>
			</li>
		<li>
				<a target="_blank" href="https://china.xilinx.com/" target="_self">
					简体中文
				</a>
			</li>
		</ul>
	</div>
																<ul class="list-inline pull-right social-menu">
																	<li>
																		<a target="_blank" href="https://www.linkedin.com/company/xilinx">
																		<span class="linkedin icon"></span>
																		<span class="sr-only">Connect on LinkedIn</span>
																		</a>
																	</li>
																	<li>
																		<a target="_blank" href="https://www.twitter.com/XilinxInc">
																		<span class="twitter icon"></span>
																		<span class="sr-only">Follow us on Twitter</span>
																		</a>
																	</li>
																	<li>
																		<a target="_blank" href="https://www.facebook.com/XilinxInc">
																		<span class="facebook icon"></span>
																		<span class="sr-only">Connect on Facebook</span>
																		</a>
																	</li>
																	<li>
																		<a target="_blank" href="https://www.youtube.com/XilinxInc">
																		<span class="youtube icon"></span>
																		<span class="sr-only">Watch us on YouTube</span>
																		</a>
																	</li>
																	<li>
																		<a target="_blank" href="https://www.xilinx.com/registration/subscriber-signup.html">
																		<span class="newsletter icon"></span>
																		<span class="sr-only">Subscribe to Newsletter</span>
																		</a>
																	</li>
																</ul>
																	<div class="lang-select dropup hidden-xs hidden-sm">
	<button data-toggle="dropdown">
		<span class="fas fa-globe" aria-hidden="true"></span>
		<span>
			
				English
			</span>
		<span class="far fa-angle-down" aria-hidden="true"></span>
	</button>
	<ul class="dropdown-menu">
		<li>
				<a target="_blank" href="https://japan.xilinx.com/" target="_self">
					日本語
				</a>
			</li>
		<li>
				<a target="_blank" href="https://china.xilinx.com/" target="_self">
					简体中文
				</a>
			</li>
		</ul>
	</div>
															</div>
														</div>
														<div class="col-md-pull-5 col-lg-pull-5 col-md-5 col-lg-5">
															<span class="copyright">©2022 Advanced Micro Devices, Inc</span>
														</div>

													</div>
													                    <div class="movethisrowtoleft row">
                        <div class="col-xs-24">
                            <ul class="sub-menu">
                                <li><a target="_blank" href="https://www.amd.com/en/corporate/copyright">Terms and Conditions</a></li>
                                <li><a target="_blank" href="https://www.amd.com/en/corporate/privacy">Privacy</a></li>
                                <li><a target="_blank" href="https://www.amd.com/en/corporate/cookies">Cookie Policy</a></li>
                                <li><a target="_blank" href="https://www.amd.com/en/corporate/trademarks">Trademarks</a></li>
                                <li><a target="_blank" href="https://www.amd.com/system/files/documents/statement-human-trafficking-forced-labor.pdf">Statement on Forced Labor</a></li>
                                <li><a target="_blank" href="https://www.amd.com/en/corporate/competition">Fair and Open Competition</a></li>
                                <li><a target="_blank" href="https://www.amd.com/system/files/documents/amd-uk-tax-strategy.pdf">UK Tax Strategy</a></li>
								<li><a target="_blank" href="https://docs.xilinx.com/v/u/9x6YvZKuWyhJId7y7RQQKA">Inclusive Terminology</a></li>
                                <li><a href="#cookiessettings" class="ot-sdk-show-settings">Cookies Settings</a></li>
                            </ul>
                        </div>
                    </div>
												</div>
											</div>
										</div>
									</footer>
								</noindex>
							</div>
						</div>
					</div>
				</div>
<div class="backToTop parbase aem-GridColumn--default--none aem-GridColumn aem-GridColumn--offset--default--0 aem-GridColumn--default--16"><noindex>
    <span data-component="backToTopButton" class="backToTopButton loaded">
        <ul>
            <li>
                <a href="https://www.author.xilinx.com/xx/rebrand/amd/en-amd-xilinx-header-footer.html#top" class="btn top">
                    <span class="fas fa-angle-up" aria-hidden="true"></span>
                </a>
            </li>
        </ul>
    </span>
</noindex></div>
			</div>
		</div>


		<script>window.CQ = window.CQ || {}</script>
		<script src="https://static.cloud.coveo.com/searchui/v2.4382/js/CoveoJsSearch.Lazy.min.js"></script>
		<script>
			var underscoreSetup = function () {
			  _.templateSettings.interpolate = /\{\{=([^-][\S\s]+?)\}\}/g;
			  _.templateSettings.evaluate = /\{\{([^-=][\S\s]+?)\}\}/g;
			  _.templateSettings.escape = /\{\{-([^=][\S\s]+?)\}\}/g;
			}

			underscoreSetup();
		</script>
	</body>
</html>