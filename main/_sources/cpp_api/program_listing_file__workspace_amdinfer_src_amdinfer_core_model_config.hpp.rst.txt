
.. _program_listing_file__workspace_amdinfer_src_amdinfer_core_model_config.hpp:

Program Listing for File model_config.hpp
=========================================

|exhale_lsh| :ref:`Return to documentation for file <file__workspace_amdinfer_src_amdinfer_core_model_config.hpp>` (``/workspace/amdinfer/src/amdinfer/core/model_config.hpp``)

.. |exhale_lsh| unicode:: U+021B0 .. UPWARDS ARROW WITH TIP LEFTWARDS

.. code-block:: cpp

   // Copyright 2023 Advanced Micro Devices, Inc.
   //
   // Licensed under the Apache License, Version 2.0 (the "License");
   // you may not use this file except in compliance with the License.
   // You may obtain a copy of the License at
   //
   //      http://www.apache.org/licenses/LICENSE-2.0
   //
   // Unless required by applicable law or agreed to in writing, software
   // distributed under the License is distributed on an "AS IS" BASIS,
   // WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   // See the License for the specific language governing permissions and
   // limitations under the License.
   
   #ifndef GUARD_AMDINFER_CORE_MODEL_CONFIG
   #define GUARD_AMDINFER_CORE_MODEL_CONFIG
   
   #include <filesystem>
   #include <string>
   #include <unordered_map>
   #include <vector>
   
   #include "amdinfer/core/parameters.hpp"
   #include "amdinfer/core/tensor.hpp"
   
   namespace toml {
   inline namespace v3 {
   class table;
   }  // namespace v3
   }  // namespace toml
   
   namespace inference {
   class Config;
   }  // namespace inference
   
   namespace amdinfer {
   
   class ModelConfigTensor : public Tensor {
    public:
     ModelConfigTensor(std::string name, std::vector<uint64_t> shape,
                       DataType data_type, std::string id);
   
     const std::string& id() const&;
     std::string id() &&;
   
    private:
     std::string id_;
   };
   
   struct ModelConfigData {
     ModelConfigData(std::string name, std::string platform, std::string id,
                     std::vector<ModelConfigTensor> inputs,
                     std::vector<ModelConfigTensor> outputs)
       : name(std::move(name)),
         platform(std::move(platform)),
         id(std::move(id)),
         inputs(std::move(inputs)),
         outputs(std::move(outputs)) {}
   
     std::string name;
     std::string platform;
     std::string id;
     std::vector<ModelConfigTensor> inputs;
     std::vector<ModelConfigTensor> outputs;
   };
   
   class ModelConfig {
     using Container = std::vector<std::pair<std::string, ParameterMap>>;
     using Iterator = Container::iterator;
     using ConstIterator = Container::const_iterator;
     using ReverseIterator = Container::reverse_iterator;
     using ConstReverseIterator = Container::const_reverse_iterator;
   
    public:
     explicit ModelConfig(const toml::v3::table& config);
     explicit ModelConfig(const inference::Config& config);
   
     std::pair<std::string, ParameterMap> get(size_t index);
     void setModelFiles(const std::filesystem::path& base_path);
   
     size_t size() const;
   
     Iterator begin();
     [[nodiscard]] ConstIterator begin() const;
     [[nodiscard]] ConstIterator cbegin() const;
     ReverseIterator rbegin();
     [[nodiscard]] ConstReverseIterator rbegin() const;
     [[nodiscard]] ConstReverseIterator crbegin() const;
   
     Iterator end();
     [[nodiscard]] ConstIterator end() const;
     [[nodiscard]] ConstIterator cend() const;
     ReverseIterator rend();
     [[nodiscard]] ConstReverseIterator rend() const;
     [[nodiscard]] ConstReverseIterator crend() const;
   
    private:
     std::vector<ModelConfigData> configs_;
     Container models_;
   
     void createModels();
   };
   
   }  // namespace amdinfer
   
   #endif  // GUARD_AMDINFER_CORE_MODEL_CONFIG
