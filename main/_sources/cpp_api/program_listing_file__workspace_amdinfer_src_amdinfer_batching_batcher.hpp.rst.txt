
.. _program_listing_file__workspace_amdinfer_src_amdinfer_batching_batcher.hpp:

Program Listing for File batcher.hpp
====================================

|exhale_lsh| :ref:`Return to documentation for file <file__workspace_amdinfer_src_amdinfer_batching_batcher.hpp>` (``/workspace/amdinfer/src/amdinfer/batching/batcher.hpp``)

.. |exhale_lsh| unicode:: U+021B0 .. UPWARDS ARROW WITH TIP LEFTWARDS

.. code-block:: cpp

   // Copyright 2021 Xilinx, Inc.
   // Copyright 2022 Advanced Micro Devices, Inc.
   //
   // Licensed under the Apache License, Version 2.0 (the "License");
   // you may not use this file except in compliance with the License.
   // You may obtain a copy of the License at
   //
   //      http://www.apache.org/licenses/LICENSE-2.0
   //
   // Unless required by applicable law or agreed to in writing, software
   // distributed under the License is distributed on an "AS IS" BASIS,
   // WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   // See the License for the specific language governing permissions and
   // limitations under the License.
   
   #ifndef GUARD_AMDINFER_BATCHING_BATCHER
   #define GUARD_AMDINFER_BATCHING_BATCHER
   
   #include <cstddef>  // for size_t
   #include <memory>   // for unique_ptr, shared_ptr
   #include <string>   // for string
   #include <thread>   // for thread
   #include <vector>   // for vector
   
   #include "amdinfer/batching/batch.hpp"       // for Batch
   #include "amdinfer/build_options.hpp"        // for AMDINFER_ENABLE_LOGGING
   #include "amdinfer/core/parameters.hpp"      // for ParameterMap
   #include "amdinfer/declarations.hpp"         // for BufferPtrs, InferenceReq...
   #include "amdinfer/observation/logging.hpp"  // for LoggerPtr
   #include "amdinfer/observation/tracing.hpp"  // for TracePtr
   #include "amdinfer/util/queue.hpp"           // for BlockingConcurrentQueue
   
   namespace amdinfer {
   class Buffer;
   class WorkerInfo;
   class MemoryPool;
   enum class MemoryAllocators;
   }  // namespace amdinfer
   
   namespace amdinfer {
   
   enum class BatcherStatus { New, Run, Inactive, Dead };
   
   using BatchPtrQueue = BlockingQueue<BatchPtr>;
   
   class Batcher {
    public:
     explicit Batcher(MemoryPool* pool);
     Batcher(MemoryPool* pool, ParameterMap* parameters);
     // explicit Batcher(const std::string& name);
     Batcher(const Batcher& batcher);              
     Batcher& operator=(const Batcher&) = delete;  
     Batcher(Batcher&& other) = delete;            
     Batcher& operator=(Batcher&& other) =
       delete;                      
     virtual ~Batcher() = default;  
   
     void start(const std::vector<MemoryAllocators>& allocator);
     void setBatchSize(size_t batch_size);
     void setName(const std::string& name);
     [[nodiscard]] std::string getName() const;
   
     BlockingQueue<RequestContainerPtr>* getInputQueue();
     BatchPtrQueue* getOutputQueue();
   
     void run(const std::vector<MemoryAllocators>& allocators);
   
     BatcherStatus getStatus() const;
   
     void enqueue(RequestContainerPtr request) const;
   
     void end();
   
    protected:
   #ifdef AMDINFER_ENABLE_LOGGING
     [[nodiscard]] const Logger& getLogger() const;
   #endif
   
     size_t batch_size_ = 1;
     std::shared_ptr<BlockingQueue<RequestContainerPtr>> input_queue_;
     std::shared_ptr<BatchPtrQueue> output_queue_;
     std::thread thread_;
     std::string model_;
     ParameterMap parameters_;
     MemoryPool* pool_;
   
    private:
     virtual void doRun(const std::vector<MemoryAllocators>& allocators) = 0;
   
     BatcherStatus status_;
   
   #ifdef AMDINFER_ENABLE_LOGGING
     Logger logger_{Loggers::Server};
   #endif
   };
   
   }  // namespace amdinfer
   
   #endif  // GUARD_AMDINFER_BATCHING_BATCHER
