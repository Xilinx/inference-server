<p>Xilinx Inference Server can be benchmarked from the command-line using the benchmarking utility.</p>
<ac:structured-macro ac:name="code">
<ac:parameter ac:name="language">bash</ac:parameter>
<ac:parameter ac:name="linenumbers">false</ac:parameter>
<ac:plain-text-body><![CDATA[proteus benchmark]]></ac:plain-text-body>
</ac:structured-macro>
<p>This command calls the benchmarking Python script in <code>tools/</code>, which will read <code>benchmark.yml</code> for the configuration and run the configurations specified. Each configuration is run a number of times and the results are analyzed and printed to the terminal. The raw data is also saved in JSON format.</p>
<p>There are multiple kinds of benchmarks that may be run:</p>
<ul>
<li>
<p>pytest: use pytest-benchmark to run Python-based benchmarks</p>
</li>
<li>
<p>wrk: use <a href="https://github.com/wg/wrk">wrk</a> for efficient benchmarking for HTTP/REST tests. These tests require running pytest for these tests first to generate the information needed by <code>wrk</code>.</p>
</li>
<li>
<p>cpp: run C++ executables</p>
</li>
</ul>
<p>Refer to <code>benchmark.yml</code> for more a detailed explanation of the different options for each type of benchmark.</p>
<h2>XModel Benchmarking</h2>
<p>The XModel test in <code>tests/cpp/native/xmodel.cpp</code> is the easiest way to benchmark an arbitrary XModel that you may want to serve with Xilinx Inference Server. It gets built as part of the regular Xilinx Inference Server build flow (for benchmarking, use the <code>--release</code> flag to build optimized executables). This test accepts a number of arguments (use <code>--help</code> to see all the options) and makes requests to Xilinx Inference Serverâ€™s backend using C++. It will print out the <abbr title="queries per second">QPS</abbr> of the requested configuration.</p>
<ac:structured-macro ac:name="code">
<ac:parameter ac:name="language">none</ac:parameter>
<ac:parameter ac:name="linenumbers">false</ac:parameter>
<ac:plain-text-body><![CDATA[$ ./build/Release/tests/cpp/native/xmodel -m <path to xmodel>]]></ac:plain-text-body>
</ac:structured-macro>
<h2>Kernel Simulation</h2>
<p>With some modifications, the Xmodel worker can be used as a way to simulate a hypothetical FPGA kernel with a certain load. Running this kind of test requires some code changes, which are described in <code>tools/xmodel_benchmark.sh</code>. With this script, you can compile the executable with different configurations and loads and print the averaged results to the terminal.</p>
