# Copyright 2022 Advanced Micro Devices, Inc.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#      http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

openapi: 3.0.3
info:
  title: AMDInfer
  description: |-
    This is the AMD Inference Server's REST API based on the OpenAPI 3.0 specification.
  license:
    name: Apache 2.0
    url: http://www.apache.org/licenses/LICENSE-2.0.html
  version: '2.0'
servers: []
tags:
  - name: health
    description: Check the health of the inference server
  - name: metadata
    description: Metadata about the inference server
  - name: models
    description: Interact with models
paths:
  /v2/:
    get:
      summary: Server Metadata
      tags: ["metadata"]
      responses:
        '200':
          description: OK
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/metadata_server_response'
        '400':
          description: Bad Request
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/metadata_server_error_response'
      operationId: get-v2
      description: 'The server metadata endpoint provides information about the server. A server metadata request is made with an HTTP GET to a server metadata endpoint. In the corresponding response the HTTP body contains the [Server Metadata Response JSON Object](#server-metadata-response-json-object) or the [Server Metadata Response JSON Error Object](#server-metadata-response-json-error-object).'
  /v2/hardware:
    post:
      summary: Has Hardware
      tags: ["metadata"]
      responses:
        '200':
          description: The server has the requested resource
        '404':
          description: The server does not have the requested resource or not enough of it
      requestBody:
        content:
          application/json:
            schema:
              $ref: '#/components/schemas/hardware'
      operationId: post-hardware
      description: 'The hardware endpoint provides information about what hardware exists and is accessible to the server. A request is made by making an HTTP POST to the hardware endpoint with the [Hardware Request JSON Object](#has-hardware-request-json-object)'
  /v2/health/live:
    get:
      summary: Server Live
      tags: ["health"]
      responses:
        '200':
          description: OK
      operationId: get-v2-health-live
      description: The "server live" API indicates if the inference server is able to receive and respond to metadata and inference requests. The "server live" API can be used directly to implement the Kubernetes livenessProbe.
  /v2/health/ready:
    get:
      summary: Server Ready
      tags: ["health"]
      responses:
        '200':
          description: OK
      operationId: get-v2-health-ready
      description: The "server ready" health API indicates if all the models are ready for inferencing. The "server ready" health API can be used directly to implement the Kubernetes readinessProbe.
  /v2/models:
    get:
      summary: Models
      tags: ["metadata", "models"]
      responses:
        '200':
          description: OK
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/model_list'
      operationId: get-models
      description: The "models" endpoint provides you a list of model endpoints that are currently available for metadata and inference
  /v2/models/${MODEL_NAME}/ready:
    parameters:
      - schema:
          type: string
        name: MODEL_NAME
        in: path
        required: true
    get:
      summary: Model Ready
      tags: ["health", "models"]
      responses:
        '200':
          description: OK
      operationId: get-v2-models-$-modelName-ready
      description: The "model ready" health API indicates if a specific model is ready for inferencing. The model name and (optionally) version must be available in the URL. If a version is not provided the server may choose a version based on its own policies. Currently, version is not supported.
  /v2/models/${MODEL_NAME}:
    parameters:
      - schema:
          type: string
        name: MODEL_NAME
        in: path
        required: true
    get:
      summary: Model Metadata
      tags: ["metadata", "models"]
      responses:
        '200':
          description: OK
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/metadata_model_response'
      operationId: get-v2-models-$-modelName
      description: The per-model metadata endpoint provides information about a model. A model metadata request is made with an HTTP GET to a model metadata endpoint. In the corresponding response the HTTP body contains the [Model Metadata Response JSON Object](#model-metadata-response-json-object) or the [Model Metadata Response JSON Error Object](#model-metadata-response-json-error-object). The model name and (optionally) version must be available in the URL. If a version is not provided the server may choose a version based on its own policies or return an error. Version is currently not supported
  /v2/models/${MODEL_NAME}/load:
    parameters:
      - schema:
          type: string
        name: MODEL_NAME
        in: path
        required: true
    post:
      tags: ["models"]
      summary: Model Load
      operationId: post-v2-models-$-MODEL_NAME-model-load
      responses:
        '200':
          description: OK
        '400':
          description: Bad Request
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/inference_error_response'
      requestBody:
        content:
          application/json:
            schema:
              $ref: '#/components/schemas/parameters'
      description: Prior to inference, a model must be loaded to serve it. A model can be loaded with an HTTP POST request to the model load endpoint. The request consists of an optional set of parameters for the model. Model load expects that the model files are already available in the expected format in the "model-repository" directory for the running server.
  /v2/models/${MODEL_NAME}/unload:
    parameters:
      - schema:
          type: string
        name: MODEL_NAME
        in: path
        required: true
    post:
      tags: ["models"]
      summary: Model Unload
      operationId: post-v2-models-$-MODEL_NAME-model-unload
      responses:
        '200':
          description: OK
        '400':
          description: Bad Request
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/inference_error_response'
      description: A model can be unloaded with an HTTP POST request to the model unload endpoint. This is identical to 'worker unload'
  /v2/workers/${WORKER_NAME}/load:
    parameters:
      - schema:
          type: string
        name: WORKER_NAME
        in: path
        required: true
    post:
      tags: ["models"]
      summary: Worker Load
      operationId: post-v2-models-$-WORKER_NAME-load
      responses:
        '200':
          description: OK
          content:
            text/html:
              example: '<html>endpoint</html>'
        '400':
          description: Bad Request
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/inference_error_response'
      requestBody:
        content:
          application/json:
            schema:
              $ref: '#/components/schemas/parameters'
      description: Prior to inference, a model must be loaded to serve it. A model can be loaded with an HTTP POST request to the worker load endpoint. The request consists of an optional set of parameters for the worker. Depending on the worker, some of these parameters may be required.
  /v2/workers/${WORKER_NAME}/unload:
    parameters:
      - schema:
          type: string
        name: WORKER_NAME
        in: path
        required: true
    post:
      tags: ["models"]
      summary: Worker Unload
      operationId: post-v2-models-$-WORKER_NAME-worker-unload
      responses:
        '200':
          description: OK
        '400':
          description: Bad Request
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/inference_error_response'
      description: A worker can be unloaded with an HTTP POST request to the worker unload endpoint. This is identical to 'model unload'
  /v2/models/${MODEL_NAME}/infer:
    parameters:
      - schema:
          type: string
        name: MODEL_NAME
        in: path
        required: true
    post:
      tags: ["models"]
      summary: Inference
      operationId: post-v2-models-$-MODEL_NAME-infer
      responses:
        '200':
          description: OK
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/inference_response'
        '400':
          description: Bad Request
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/inference_error_response'
      requestBody:
        content:
          application/json:
            schema:
              $ref: '#/components/schemas/inference_request'
      description: 'An inference request is made with an HTTP POST to an inference endpoint. In the request the HTTP body contains the [Inference Request JSON Object](#inference-request-json-object). In the corresponding response the HTTP body contains the [Inference Response JSON Object](#inference-response-json-object) or [Inference Response JSON Error Object](#inference-response-json-error-object). See [Inference Request Examples](#inference-request-examples) for some example HTTP/REST requests and responses.'
  /metrics:
    get:
      tags: ["metadata"]
      summary: Metrics
      operationId: get-v2-metrics
      responses:
        '200':
          description: OK
          content:
            text/html:
              example: '<html>metrics...</html>'
      description: Get Prometheus-styled metrics from the server
components:
  schemas:
    metadata_server_response:
      title: metadata_server_response
      type: object
      description: ''
      x-examples: {}
      properties:
        name:
          type: string
        version:
          type: string
        extensions:
          type: array
          items:
            type: string
      required:
        - name
        - version
        - extensions
    metadata_server_error_response:
      title: metadata_server_error_response
      type: object
      properties:
        error:
          type: string
      required:
        - error
    metadata_model_response:
      title: metadata_model_response
      type: object
      properties:
        name:
          type: string
        versions:
          type: array
          items:
            type: string
        platform:
          type: string
        inputs:
          type: array
          items:
            $ref: '#/components/schemas/metadata_tensor'
        outputs:
          type: array
          items:
            $ref: '#/components/schemas/metadata_tensor'
      required:
        - name
        - platform
    metadata_tensor:
      title: metadata_tensor
      type: object
      properties:
        name:
          type: string
        datatype:
          type: string
        shape:
          type: array
          items:
            type: integer
      required:
        - name
        - datatype
        - shape
    metadata_model_error_response:
      title: metadata_model_error_response
      type: object
      properties:
        error:
          type: string
      required:
        - error
    inference_request:
      title: inference_request
      type: object
      x-examples:
        Example 1:
          id: '42'
          inputs:
            - name: input0
              shape:
                - 2
                - 2
              datatype: UINT32
              data:
                - 1
                - 2
                - 3
                - 4
            - name: input1
              shape:
                - 3
              datatype: BOOL
              data:
                - true
          outputs:
            - name: output0
        Example 2:
          id: '42'
          outputs:
            - name: output0
              shape:
                - 3
                - 2
              datatype: FP32
              data:
                - 1
                - 1.1
                - 2
                - 2.1
                - 3
                - 3.1
      properties:
        id:
          type: string
        parameters:
          $ref: '#/components/schemas/parameters'
        inputs:
          type: array
          items:
            $ref: '#/components/schemas/request_input'
        outputs:
          type: array
          items:
            $ref: '#/components/schemas/request_output'
      required:
        - inputs
    parameters:
      title: parameters
      x-examples: {}
      type: object
      items:
        anyOf:
          - type: number
          - type: string
          - type: boolean
    request_input:
      title: request_input
      type: object
      properties:
        name:
          type: string
        shape:
          type: array
          items:
            type: integer
        datatype:
          type: string
        parameters:
          $ref: '#/components/schemas/parameters'
        data:
          $ref: '#/components/schemas/tensor_data'
      required:
        - name
        - shape
        - datatype
        - data
    tensor_data:
      title: tensor_data
      type: array
      items:
        anyOf:
          - $ref: '#/components/schemas/tensor_data'
          - type: number
          - type: string
          - type: boolean
    request_output:
      title: request_output
      type: object
      properties:
        name:
          type: string
        parameters:
          $ref: '#/components/schemas/parameters'
      required:
        - name
    response_output:
      title: response_output
      type: object
      properties:
        name:
          type: string
        shape:
          type: array
          items:
            type: integer
        datatype:
          type: string
        parameters:
          $ref: '#/components/schemas/parameters'
        data:
          $ref: '#/components/schemas/tensor_data'
      required:
        - name
        - shape
        - datatype
        - data
    inference_response:
      title: inference_response
      type: object
      properties:
        model_name:
          type: string
        model_version:
          type: string
        id:
          type: string
        parameters:
          $ref: '#/components/schemas/parameters'
        outputs:
          type: array
          items:
            $ref: '#/components/schemas/response_output'
      required:
        - model_name
        - outputs
    inference_error_response:
      title: inference_error_response
      type: object
      properties:
        error:
          type: string
    hardware:
      title: hardware
      type: object
      properties:
        name:
          type: string
        num:
          type: integer
      required:
        - name
        - num
    model_list:
      title: model_list
      type: array
      items:
        type: string
