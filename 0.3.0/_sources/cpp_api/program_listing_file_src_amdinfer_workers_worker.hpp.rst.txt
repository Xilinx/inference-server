
.. _program_listing_file_src_amdinfer_workers_worker.hpp:

Program Listing for File worker.hpp
===================================

|exhale_lsh| :ref:`Return to documentation for file <file_src_amdinfer_workers_worker.hpp>` (``src/amdinfer/workers/worker.hpp``)

.. |exhale_lsh| unicode:: U+021B0 .. UPWARDS ARROW WITH TIP LEFTWARDS

.. code-block:: cpp

   // Copyright 2021 Xilinx, Inc.
   // Copyright 2022 Advanced Micro Devices, Inc.
   //
   // Licensed under the Apache License, Version 2.0 (the "License");
   // you may not use this file except in compliance with the License.
   // You may obtain a copy of the License at
   //
   //      http://www.apache.org/licenses/LICENSE-2.0
   //
   // Unless required by applicable law or agreed to in writing, software
   // distributed under the License is distributed on an "AS IS" BASIS,
   // WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   // See the License for the specific language governing permissions and
   // limitations under the License.
   
   #ifndef GUARD_AMDINFER_WORKERS_WORKER
   #define GUARD_AMDINFER_WORKERS_WORKER
   
   #include <limits>
   #include <memory>
   #include <string>
   #include <thread>
   #include <utility>
   #include <vector>
   
   #include "amdinfer/batching/soft.hpp"
   #include "amdinfer/buffers/buffer.hpp"
   #include "amdinfer/build_options.hpp"
   #include "amdinfer/core/predict_api.hpp"
   #include "amdinfer/observation/logging.hpp"
   
   namespace amdinfer {
   
   constexpr auto kNumBufferAuto = -1;
   
   namespace workers {
   
   enum class WorkerStatus {
     kNew,
     kInit,
     kAllocate,
     kAcquire,
     kRun,
     kInactive,
     kRelease,
     kDeallocate,
     kDestroy,
     kDead
   };
   
   class Worker {
    public:
     Worker(const std::string& name, const std::string& platform)
       : metadata_(name, platform) {
       this->status_ = WorkerStatus::kNew;
       this->input_buffers_ = nullptr;
       this->output_buffers_ = nullptr;
       this->max_buffer_num_ = UINT_MAX;
       this->batch_size_ = 1;
     }
     virtual ~Worker() = default;  
   
     virtual std::thread spawn(BatchPtrQueue* input_queue) = 0;
   
     void init(RequestParameters* parameters) {
       this->status_ = WorkerStatus::kInit;
       this->doInit(parameters);
     }
     size_t allocate(size_t num) {
       this->status_ = WorkerStatus::kAllocate;
       return this->doAllocate(num);
     }
     void acquire(RequestParameters* parameters) {
       this->status_ = WorkerStatus::kAcquire;
       this->doAcquire(parameters);
       this->metadata_.setReady(true);
     }
     void run(BatchPtrQueue* input_queue) {
       this->status_ = WorkerStatus::kRun;
       this->doRun(input_queue);
       this->status_ = WorkerStatus::kInactive;
     }
     void release() {
       this->status_ = WorkerStatus::kRelease;
       this->metadata_.setReady(false);
       this->doRelease();
     }
     void deallocate() {
       this->status_ = WorkerStatus::kDeallocate;
       this->doDeallocate();
       this->input_buffers_ = nullptr;
       this->output_buffers_ = nullptr;
     }
     void destroy() {
       this->status_ = WorkerStatus::kDestroy;
       this->doDestroy();
       this->status_ = WorkerStatus::kDead;
     }
   
     void returnBuffers(std::unique_ptr<std::vector<BufferPtrs>> input_buffers,
                        std::unique_ptr<std::vector<BufferPtrs>> output_buffers) {
       this->input_buffers_->enqueue_bulk(
         std::make_move_iterator(input_buffers->begin()), input_buffers->size());
       this->output_buffers_->enqueue_bulk(
         std::make_move_iterator(output_buffers->begin()), output_buffers->size());
     }
   
     void setInputBuffers(BufferPtrsQueue* buffers) {
       this->input_buffers_ = buffers;
     }
   
     void setOutputBuffers(BufferPtrsQueue* buffers) {
       this->output_buffers_ = buffers;
     }
   
     [[nodiscard]] uint32_t getMaxBufferNum() const {
       return this->max_buffer_num_;
     }
   
     [[nodiscard]] size_t getBatchSize() const { return this->batch_size_; }
     [[nodiscard]] WorkerStatus getStatus() const { return this->status_; }
   
     virtual std::vector<std::unique_ptr<Batcher>> makeBatcher(
       int num, RequestParameters* parameters) {
       return this->makeBatcher<SoftBatcher>(num, parameters);
     }
   
     template <typename T>
     std::vector<std::unique_ptr<Batcher>> makeBatcher(
       int num, RequestParameters* parameters) {
       std::vector<std::unique_ptr<Batcher>> batchers;
       batchers.emplace_back(std::make_unique<T>(parameters));
       for (int i = 1; i < num; i++) {
         batchers.push_back(
           std::make_unique<T>(*dynamic_cast<T*>(batchers.back().get())));
       }
       return batchers;
     }
   
     ModelMetadata getMetadata() { return this->metadata_; }
   
    protected:
   #ifdef AMDINFER_ENABLE_LOGGING
     const Logger& getLogger() const { return logger_; };
   #endif
   
     BufferPtrsQueue* input_buffers_;
     BufferPtrsQueue* output_buffers_;
     uint32_t max_buffer_num_;
     size_t batch_size_;
     ModelMetadata metadata_;
   
    private:
     virtual void doInit(RequestParameters* parameters) = 0;
     virtual size_t doAllocate(size_t num) = 0;
     virtual void doAcquire(RequestParameters* parameters) = 0;
     virtual void doRun(BatchPtrQueue* input_queue) = 0;
     virtual void doRelease() = 0;
     virtual void doDeallocate() = 0;
     virtual void doDestroy() = 0;
   
   #ifdef AMDINFER_ENABLE_LOGGING
     Logger logger_{Loggers::kServer};
   #endif
   
     WorkerStatus status_;
   };
   
   }  // namespace workers
   
   }  // namespace amdinfer
   
   #endif  // GUARD_AMDINFER_WORKERS_WORKER
